{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyl/miniconda3/envs/videollm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "EGO_ROOT = '/home/zhangyl/videollm-online/datasets/ego4d/'\n",
    "CAPTION_ROOT = '/home/zhangyl/videollm-online/datasets/ego4d_action_caption'\n",
    "MOVE_CAPTION_ROOT = '/home/zhangyl/videollm-online/datasets/ego4d_move_action_caption'\n",
    "SCENE_CAPTION_ROOT = '/home/zhangyl/videollm-online/datasets/ego4d_scene_caption'\n",
    "\n",
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from video_caption_action_scene import AnnotationLoader, BetaAlphaCalculator\n",
    "\n",
    "EGO_VERSION_ROOT = os.path.join(EGO_ROOT, 'v2')\n",
    "json_path = os.path.join(EGO_ROOT, 'ego4d.json')\n",
    "train_path = f'{EGO_VERSION_ROOT}/annotations/refined_narration_stream_train.json'\n",
    "val_path = f'{EGO_VERSION_ROOT}/annotations/refined_narration_stream_val.json'\n",
    "origin_path = f'{EGO_VERSION_ROOT}/annotations/all_narrations_redacted.json'\n",
    "video_root = f'{EGO_VERSION_ROOT}/full_scale_2fps'\n",
    "alpha = 4.9\n",
    "device = 'cuda:3'\n",
    "caption_dir = '/root/videollm-online/tmp5'\n",
    "\n",
    "annotation_loader = AnnotationLoader(train_path, val_path, origin_path, json_path)\n",
    "data = annotation_loader.get_data()\n",
    "origin_narration = annotation_loader.get_origin_narration()\n",
    "\n",
    "beta_alpha_calculator = BetaAlphaCalculator(data, alpha)\n",
    "beta_alpha_calculator.compute_beta()\n",
    "beta_map = beta_alpha_calculator.get_beta_map()\n",
    "alpha = beta_alpha_calculator.get_alpha()\n",
    "\n",
    "train_caption = json.load(open(f'{CAPTION_ROOT}/action_caption_train.json'))\n",
    "val_caption = json.load(open(f'{CAPTION_ROOT}/action_caption_val.json'))\n",
    "all_caption = {**train_caption, **val_caption}\n",
    "\n",
    "move_train_caption = json.load(open(f'{MOVE_CAPTION_ROOT}/action_caption_train.json'))\n",
    "move_val_caption = json.load(open(f'{MOVE_CAPTION_ROOT}/action_caption_val.json'))\n",
    "move_all_caption = {**move_train_caption, **move_val_caption}\n",
    "\n",
    "scene_train_caption = json.load(open(f'{SCENE_CAPTION_ROOT}/action_caption_train.json'))\n",
    "scene_val_caption = json.load(open(f'{SCENE_CAPTION_ROOT}/action_caption_val.json'))\n",
    "scene_all_caption = {**scene_train_caption, **scene_val_caption}\n",
    "\n",
    "video2scene = json.load(open('/home/zhangyl/videollm-online/data/estp/ego4d/metafile/video2scene.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video2scene = json.load(open('/home/zhangyl/videollm-online/data/estp/ego4d/metafile/video2scene.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_caption_wo_action(captions, video_uid, clip_uid, video2scene, origin_narration, w_pre = False):\n",
    "    caption = captions[video_uid][clip_uid]\n",
    "    \n",
    "    caption_texts = {}\n",
    "    for action_idx, cap in enumerate(caption):\n",
    "        \n",
    "        caption_texts[action_idx] = {\n",
    "            'caption': cap['caption'],\n",
    "            'reason': None,\n",
    "            'is_relational': None,\n",
    "        }\n",
    "        \n",
    "    return caption_texts\n",
    "\n",
    "def merge_narration(data, video_uid, clip_uid, video2scene, origin_narration, w_pre = False):\n",
    "    narration = data[video_uid][clip_uid]\n",
    "    \n",
    "    caption_texts = {}\n",
    "    for action_idx, nar in enumerate(narration):\n",
    "        \n",
    "        caption_texts[action_idx] = {\n",
    "            'caption': nar['text'],\n",
    "            'reason': None,\n",
    "            'is_relational': None,\n",
    "        }\n",
    "        \n",
    "    return caption_texts\n",
    "\n",
    "def merge_caption_with_action(captions, narrations, video_uid, clip_uid, video2scene, origin_narration):\n",
    "    narration = narrations[video_uid][clip_uid]\n",
    "    caption = captions[video_uid][clip_uid]\n",
    "    \n",
    "    caption_texts = \"\"\n",
    "    for action_idx, (nar, cap) in enumerate(zip(narration, caption)):\n",
    "        action_narration = 'Idx is {}, Time is {}. Action narration is \\\"'.format(action_idx, nar['time']) + nar['text'] + '\\\".\\n'\n",
    "        caption_text = 'Detailed Description: \\\"' + cap['text'] + '\\\" \\n'\n",
    "        caption_text = action_narration + caption_text\n",
    "        caption_texts += caption_text + '\\n'\n",
    "    \n",
    "    return caption_texts\n",
    "\n",
    "def caption_merger(captions, video2scene, origin_narration):\n",
    "    for video_uid in captions.keys():\n",
    "        for clip_uid in captions[video_uid].keys():\n",
    "            caption_texts = merge_caption_wo_action(captions, video_uid, clip_uid, video2scene, origin_narration)\n",
    "            yield caption_texts, video_uid, clip_uid\n",
    "\n",
    "def read_qa(video_uid, clip_uid, qas):\n",
    "    qa = qas[video_uid][clip_uid]\n",
    "    return qa\n",
    "\n",
    "def transformqa(qa):\n",
    "    qa_text = []\n",
    "    for q in qa:\n",
    "        if 'visual_cues' in q:\n",
    "            qa_text.append({\n",
    "                'question': q['question'],\n",
    "                # 'answer': q['conversation'][0]['content'],\n",
    "                'visual_cues': q['visual_cues'],\n",
    "            })\n",
    "        else:\n",
    "            qa_text.append({\n",
    "                'question': q['question'],\n",
    "                'answer': q['conversation'][0]['content'],\n",
    "            })\n",
    "    return qa_text\n",
    "\n",
    "def qa_gentor(qas):\n",
    "    for k,v in qas.items():\n",
    "        for kk,vv in qas[k].items():\n",
    "            yield k,kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 24 column 1 (char 1038)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m     question \u001b[38;5;241m=\u001b[39m user_prompt\u001b[38;5;241m.\u001b[39mformat(json\u001b[38;5;241m.\u001b[39mdumps(sample_caption_text,indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m), json\u001b[38;5;241m.\u001b[39mdumps(qa, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     59\u001b[0m     answer \u001b[38;5;241m=\u001b[39m get_llm_reponse_json(system_prompt, question)\n\u001b[0;32m---> 60\u001b[0m     final_answer\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     62\u001b[0m question \u001b[38;5;241m=\u001b[39m user_prompt\u001b[38;5;241m.\u001b[39mformat(json\u001b[38;5;241m.\u001b[39mdumps(caption_texts,indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m), json\u001b[38;5;241m.\u001b[39mdumps(qa, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))   \n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_uid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclip_uid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_caption.txt\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniconda3/envs/videollm/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/videollm/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/envs/videollm/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 24 column 1 (char 1038)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "def get_llm_reponse_json(system_prompt, user_prompt):\n",
    "    client = OpenAI(\n",
    "            api_key=\"\",\n",
    "            base_url=\"https://api.deepseek.com\",\n",
    "        )\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages,\n",
    "        response_format={\n",
    "            'type': 'json_object'\n",
    "        }\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "anno_file = 'c_soc_annos_v2'\n",
    "postfix = 'judge'\n",
    "mode = 'narration'\n",
    "\n",
    "\n",
    "qas = json.load(open(f'/home/zhangyl/videollm-online/data/estp/annotations/{anno_file}.json'))\n",
    "_qa_gentor = qa_gentor(qas)\n",
    "prompt_version = 3\n",
    "\n",
    "output_dir = f'/home/zhangyl/videollm-online/dataset/{anno_file}_{postfix}_{mode}/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "system_prompt = open(f'/home/zhangyl/videollm-online/data/estp/ego4d/prompt/judge_relative_system_prompt_v{prompt_version}.txt').read()\n",
    "user_prompt = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/judge_relative_user_prompt.txt').read()\n",
    "step = 10\n",
    "\n",
    "for n_sample in range(0,50):\n",
    "    video_uid, clip_uid = next(_qa_gentor)\n",
    "    # try:\n",
    "    if mode == 'action':\n",
    "        caption_texts = merge_caption_wo_action(all_caption, video_uid, clip_uid, video2scene, origin_narration)\n",
    "    elif mode == 'scene':\n",
    "        caption_texts = merge_caption_wo_action(scene_all_caption, video_uid, clip_uid, video2scene, origin_narration)\n",
    "    elif mode == 'move_action':\n",
    "        caption_texts = merge_caption_wo_action(move_all_caption, video_uid, clip_uid, video2scene, origin_narration)\n",
    "    elif mode == 'narration':\n",
    "        caption_texts = merge_narration(data, video_uid, clip_uid, video2scene, origin_narration)\n",
    "    # except:\n",
    "    #     continue\n",
    "    \n",
    "    qa_list = transformqa(read_qa(video_uid, clip_uid, qas))\n",
    "\n",
    "    \n",
    "    for i,qa in enumerate(qa_list):\n",
    "\n",
    "        n_caption = len(caption_texts.keys())\n",
    "        final_answer = {}\n",
    "        for j in range(0, n_caption, step):\n",
    "            sample_caption_text = {k:v for k, v in caption_texts.items() if j <= k < j+step}\n",
    "            question = user_prompt.format(json.dumps(sample_caption_text,indent=4), json.dumps(qa, indent=4))\n",
    "            answer = get_llm_reponse_json(system_prompt, question)\n",
    "            final_answer.update(json.loads(answer))\n",
    "        \n",
    "        question = user_prompt.format(json.dumps(caption_texts,indent=4), json.dumps(qa, indent=4))   \n",
    "        with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_{i}_caption.txt'), 'w') as f:\n",
    "            f.write(question)\n",
    "        with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_{i}_judge.json'), 'w') as f:\n",
    "            json.dump(final_answer, f, indent=4)\n",
    "        \n",
    "        break\n",
    "    print(n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/home/zhangyl/videollm-online/dataset/move_action_function_v7_judge_v4/'\n",
    "caption_merger1 = caption_merger(move_all_caption, video2scene, origin_narration)\n",
    "caption_texts, video_uid, clip_uid = next(caption_merger1)\n",
    "caption_texts, video_uid, clip_uid = next(caption_merger1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3d8f5230-0c22-4018-86b0-e6d851b74b11 56f7f97d-4be8-4778-8d0e-ab4811b75add\n",
      "[\n",
      "    {\n",
      "        \"Task Type\": \"Information Function\",\n",
      "        \"question\": \"I need to proceed safely. What should I be aware of?\",\n",
      "        \"visual_cues\": \"The red car with the triangular sign, its position relative to your vehicle, and the slow or stationary movement.\",\n",
      "        \"conversation\": [\n",
      "            {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"There is a red car ahead with a triangular warning sign, indicating a potential hazard or need for caution. It is either stationary or moving very slowly. Proceed carefully and wait for the situation to resolve before moving forward.\",\n",
      "                \"time\": 288.2834986550782,\n",
      "                \"start_time\": 286.32570171630266,\n",
      "                \"end_time\": 290.2412955938537\n",
      "            }\n",
      "        ],\n",
      "        \"clip_start_time\": 268.94702005507816,\n",
      "        \"clip_end_time\": 569.9670286\n",
      "    },\n",
      "    {\n",
      "        \"Task Type\": \"Object Function\",\n",
      "        \"question\": \"I need to check the traffic behind me. Where should I look?\",\n",
      "        \"visual_cues\": \"The side mirror's position and the reflections of other vehicles in the parking lot.\",\n",
      "        \"conversation\": [\n",
      "            {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"The side mirror on the right side of the frame reflects the road behind and to the sides. Look there to observe the traffic flow and ensure it is safe to proceed.\",\n",
      "                \"time\": 288.2834986550782,\n",
      "                \"start_time\": 286.32570171630266,\n",
      "                \"end_time\": 290.2412955938537\n",
      "            }\n",
      "        ],\n",
      "        \"clip_start_time\": 268.94702005507816,\n",
      "        \"clip_end_time\": 569.9670286\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"caption\": \"The video provides a first-person perspective from inside a car, capturing the driver's view as they navigate through various environments. Here is a detailed description of the environment and objects in the scene:\\n\\n### Object Positioning:\\n- **Steering Wheel**: Central to the frame, with hands on it throughout the video.\\n- **Dashboard**: Contains various controls and displays, including air vents, radio, and speedometer.\\n- **Side Mirror**: Visible on both sides of the frame, reflecting the surroundings.\\n- **Windshield**: Provides a clear view of the road ahead.\\n- **Windows**: Allow visibility of the outside environment, showing other vehicles and landscapes.\\n\\n### Relative Positioning of Objects:\\n- The dashboard items are positioned directly in front of the observer, with the steering wheel centrally located.\\n- The side mirrors show reflections that change as the car moves, indicating relative positions of surrounding cars and scenery.\\n- The windshield offers a forward-facing view, while the windows reveal peripheral views.\\n\\n### Camera Movement and Object Position Change:\\n- The camera remains fixed within the car but captures different scenes as the vehicle moves.\\n- As the car drives, the position of external objects like other vehicles and roadside features shifts relative to the camera.\\n- For instance, when turning or stopping, the angle changes, altering the visibility and positioning of objects such as traffic signs, road markings, and adjacent cars.\\n\\n### Interactions and Movements:\\n- **Driving Actions**: The movements include driving straight, making turns, and stopping at intersections.\\n- **Environmental Interaction**: The car interacts with its surroundings by navigating through parking lots, streets, and highways.\\n- **Traffic Dynamics**: Other vehicles' movement affects the scene, with overtaking maneuvers and maintaining lane positions evident.\\n- **Scenic Changes**: The landscape transitions from urban settings with buildings and shops to more open roads with natural scenery.\\n\\nThroughout the video, the consistent presence of the car\\u2019s interior elements (steering wheel, dashboard) alongside changing external views creates a dynamic narrative of travel and navigation.\",\n",
      "        \"start_time\": 0.0210286,\n",
      "        \"end_time\": 284.44621665507816,\n",
      "        \"pre_scene\": true,\n",
      "        \"text\": \"The video provides a first-person perspective from inside a car, capturing the driver's view as they navigate through various environments. Here is a detailed description of the environment and objects in the scene:\\n\\n### Object Positioning:\\n- **Steering Wheel**: Central to the frame, with hands on it throughout the video.\\n- **Dashboard**: Contains various controls and displays, including air vents, radio, and speedometer.\\n- **Side Mirror**: Visible on both sides of the frame, reflecting the surroundings.\\n- **Windshield**: Provides a clear view of the road ahead.\\n- **Windows**: Allow visibility of the outside environment, showing other vehicles and landscapes.\\n\\n### Relative Positioning of Objects:\\n- The dashboard items are positioned directly in front of the observer, with the steering wheel centrally located.\\n- The side mirrors show reflections that change as the car moves, indicating relative positions of surrounding cars and scenery.\\n- The windshield offers a forward-facing view, while the windows reveal peripheral views.\\n\\n### Camera Movement and Object Position Change:\\n- The camera remains fixed within the car but captures different scenes as the vehicle moves.\\n- As the car drives, the position of external objects like other vehicles and roadside features shifts relative to the camera.\\n- For instance, when turning or stopping, the angle changes, altering the visibility and positioning of objects such as traffic signs, road markings, and adjacent cars.\\n\\n### Interactions and Movements:\\n- **Driving Actions**: The movements include driving straight, making turns, and stopping at intersections.\\n- **Environmental Interaction**: The car interacts with its surroundings by navigating through parking lots, streets, and highways.\\n- **Traffic Dynamics**: Other vehicles' movement affects the scene, with overtaking maneuvers and maintaining lane positions evident.\\n- **Scenic Changes**: The landscape transitions from urban settings with buildings and shops to more open roads with natural scenery.\\n\\nThroughout the video, the consistent presence of the car\\u2019s interior elements (steering wheel, dashboard) alongside changing external views creates a dynamic narrative of travel and navigation.\",\n",
      "        \"time\": 284.44621665507816\n",
      "    },\n",
      "    {\n",
      "        \"caption\": \"The video captures a first-person perspective from inside a vehicle, focusing on the view through the windshield and side window. The scene is set in an outdoor environment during daytime with clear skies.\\n\\n1. **Object Positioning**:\\n   - The steering wheel is prominently visible at the bottom center of the frame, indicating that the camera is positioned within the driver's seat.\\n   - Through the windshield, there is another car parked or moving slowly ahead, which has a distinctive triangular warning sign attached to its rear door. This car is consistently visible throughout the video.\\n   - On the right side of the frame, the side mirror reflects the road behind and to the sides, showing other vehicles and parts of the parking lot.\\n\\n2. **Relative Positioning of Objects**:\\n   - The red car with the triangular sign remains stationary or moves very slowly relative to the observer's vehicle.\\n   - The background shows various elements such as trees, buildings, and other cars parked in the distance, all under natural daylight conditions.\\n\\n3. **Camera Movement and Object Position Change**:\\n   - As the video progresses, the camera slightly shifts, possibly due to minor adjustments made by the driver. This shift affects the visibility of objects outside the car, particularly the position of the red car and the surrounding environment.\\n   - There is no significant change in the positioning of the red car; it appears to be either parked or moving slowly in place relative to the viewer's vehicle.\\n   - The side mirror occasionally reveals changes in the traffic flow behind the observer\\u2019s vehicle, indicating slight movements of other cars.\\n\\n4. **Interactions and Movements**:\\n   - The primary interaction observed is between the two vehicles: the one with the triangular sign and the observer's vehicle. The observer's vehicle seems to be waiting for the red car to move or for the situation to resolve before proceeding.\\n   - No significant actions are taken by any object other than subtle adjustments likely made by the driver, such as shifting the hand on the steering wheel or making minor adjustments to the driving posture.\\n\\nThroughout the video, the environment remains consistent, characterized by a calm and sunny day with minimal activity aside from the slight movements of the vehicles involved.\",\n",
      "        \"stamp_time\": 288.2834986550782,\n",
      "        \"start_time\": 284.44621665507816,\n",
      "        \"end_time\": 292.1207806550782,\n",
      "        \"simi\": 0.777002215385437,\n",
      "        \"action_narration\": \"You drive a car on the road.\",\n",
      "        \"action_idx\": 1,\n",
      "        \"text\": \"The video captures a first-person perspective from inside a vehicle, focusing on the view through the windshield and side window. The scene is set in an outdoor environment during daytime with clear skies.\\n\\n1. **Object Positioning**:\\n   - The steering wheel is prominently visible at the bottom center of the frame, indicating that the camera is positioned within the driver's seat.\\n   - Through the windshield, there is another car parked or moving slowly ahead, which has a distinctive triangular warning sign attached to its rear door. This car is consistently visible throughout the video.\\n   - On the right side of the frame, the side mirror reflects the road behind and to the sides, showing other vehicles and parts of the parking lot.\\n\\n2. **Relative Positioning of Objects**:\\n   - The red car with the triangular sign remains stationary or moves very slowly relative to the observer's vehicle.\\n   - The background shows various elements such as trees, buildings, and other cars parked in the distance, all under natural daylight conditions.\\n\\n3. **Camera Movement and Object Position Change**:\\n   - As the video progresses, the camera slightly shifts, possibly due to minor adjustments made by the driver. This shift affects the visibility of objects outside the car, particularly the position of the red car and the surrounding environment.\\n   - There is no significant change in the positioning of the red car; it appears to be either parked or moving slowly in place relative to the viewer's vehicle.\\n   - The side mirror occasionally reveals changes in the traffic flow behind the observer\\u2019s vehicle, indicating slight movements of other cars.\\n\\n4. **Interactions and Movements**:\\n   - The primary interaction observed is between the two vehicles: the one with the triangular sign and the observer's vehicle. The observer's vehicle seems to be waiting for the red car to move or for the situation to resolve before proceeding.\\n   - No significant actions are taken by any object other than subtle adjustments likely made by the driver, such as shifting the hand on the steering wheel or making minor adjustments to the driving posture.\\n\\nThroughout the video, the environment remains consistent, characterized by a calm and sunny day with minimal activity aside from the slight movements of the vehicles involved.\",\n",
      "        \"time\": 292.1207806550782\n",
      "    },\n",
      "    {\n",
      "        \"caption\": \"The video captures a first-person perspective from inside a vehicle, focusing on the driver's view of the road ahead and the interior dashboard. Here is a detailed description of the environment and objects in the scene:\\n\\n1. **Interior Dashboard:**\\n   - The steering wheel is prominently positioned at the center, with the car's logo in the middle.\\n   - To the left of the steering wheel, there are air vents and control buttons for the climate system.\\n   - In front of the driver, there is an infotainment screen displaying information, which remains consistent throughout the clip.\\n   - The speedometer and other instrument clusters are visible behind the steering wheel.\\n\\n2. **Driver\\u2019s Hand:**\\n   - A hand is seen holding the steering wheel, indicating that the person is driving. This hand occasionally moves to interact with controls on the steering column or gear shift area.\\n\\n3. **Road and Surroundings:**\\n   - Through the windshield and side windows, we see a road lined with trees and some buildings, suggesting a suburban or semi-urban setting.\\n   - Traffic includes various vehicles such as cars and possibly trucks, moving in both directions.\\n   - The road has clear lane markings, and the traffic appears to be flowing smoothly without any significant congestion.\\n\\n4. **Camera Movement and Object Position Change:**\\n   - The camera angle remains constant from the driver's perspective, capturing the forward view through the windshield and the immediate surroundings.\\n   - As the vehicle moves forward, the position of other vehicles relative to the car changes slightly, indicating motion.\\n   - There is no noticeable panning or zooming; the focus stays on the straight-ahead view.\\n\\n5. **Interactions and Movements:**\\n   - The primary interaction observed is the driver's hands adjusting positions on the steering wheel and potentially engaging with vehicle controls.\\n   - Other than this, there are no significant movements or interactions between objects within the vehicle or outside it, maintaining a steady driving scenario.\\n\\nIn summary, the video provides a continuous first-person view of a drive down a relatively empty road, with attention to the driver's actions and the surrounding environment.\",\n",
      "        \"start_time\": 292.1207806550782,\n",
      "        \"end_time\": 552.9129166550782,\n",
      "        \"pre_scene\": true,\n",
      "        \"text\": \"The video captures a first-person perspective from inside a vehicle, focusing on the driver's view of the road ahead and the interior dashboard. Here is a detailed description of the environment and objects in the scene:\\n\\n1. **Interior Dashboard:**\\n   - The steering wheel is prominently positioned at the center, with the car's logo in the middle.\\n   - To the left of the steering wheel, there are air vents and control buttons for the climate system.\\n   - In front of the driver, there is an infotainment screen displaying information, which remains consistent throughout the clip.\\n   - The speedometer and other instrument clusters are visible behind the steering wheel.\\n\\n2. **Driver\\u2019s Hand:**\\n   - A hand is seen holding the steering wheel, indicating that the person is driving. This hand occasionally moves to interact with controls on the steering column or gear shift area.\\n\\n3. **Road and Surroundings:**\\n   - Through the windshield and side windows, we see a road lined with trees and some buildings, suggesting a suburban or semi-urban setting.\\n   - Traffic includes various vehicles such as cars and possibly trucks, moving in both directions.\\n   - The road has clear lane markings, and the traffic appears to be flowing smoothly without any significant congestion.\\n\\n4. **Camera Movement and Object Position Change:**\\n   - The camera angle remains constant from the driver's perspective, capturing the forward view through the windshield and the immediate surroundings.\\n   - As the vehicle moves forward, the position of other vehicles relative to the car changes slightly, indicating motion.\\n   - There is no noticeable panning or zooming; the focus stays on the straight-ahead view.\\n\\n5. **Interactions and Movements:**\\n   - The primary interaction observed is the driver's hands adjusting positions on the steering wheel and potentially engaging with vehicle controls.\\n   - Other than this, there are no significant movements or interactions between objects within the vehicle or outside it, maintaining a steady driving scenario.\\n\\nIn summary, the video provides a continuous first-person view of a drive down a relatively empty road, with attention to the driver's actions and the surrounding environment.\",\n",
      "        \"time\": 552.9129166550782\n",
      "    }\n",
      "]\n",
      "Idx is 0, Time is 268.95404865507817. Action narration is \"You look around.\".\n",
      "Detailed Description: \"As you look around, the interior of the car is bathed in sunlight streaming through the windows. The dashboard is a sleek black with illuminated dials and controls. You notice the steering wheel prominently in front of you, featuring the logo of the vehicle's brand. Outside the window, a clear blue sky stretches above, casting shadows on the road below. Buildings line the street, trees dotting the landscape, and a traffic light stands sentinel at an intersection ahead. A sense of calm pervades the scene as the car remains stationary for now.\" \n",
      "\n",
      "Idx is 1, Time is 288.2834986550782. Action narration is \"You drive a car on the road.\".\n",
      "Detailed Description: \"As you drive a car on the road, your hands firmly grip the steering wheel as it smoothly guides through the traffic. The dashboard in front of you displays various gauges and indicators, while the rearview mirror reflects the scene behind you. Through the side window, you notice another red car with a triangular warning sign attached to its door, indicating some caution or maintenance needed. The environment outside is bright and sunny, casting clear shadows on the pavement. As the car continues its journey, other vehicles appear in view, including white cars driving ahead and parked along the roadside.\" \n",
      "\n",
      "Idx is 2, Time is 336.5999786550782. Action narration is \"You look around.\".\n",
      "Detailed Description: \"As you look around, the bustling cityscape unfolds before your eyes. Towering buildings with varying architectural styles line the streets, their facades reflecting the bright sunlight. The sky above is a clear azure, devoid of any clouds, suggesting it's a perfect day for driving.\n",
      "\n",
      "In front of you, a vibrant red car catches your attention, its glossy exterior gleaming under the sun. Further ahead, a pedestrian crossing sign stands prominently at an intersection, guiding both vehicles and pedestrians alike. A green traffic light glows brightly, signaling the cars to proceed through the junction safely.\n",
      "\n",
      "To your left, a blue bus is visible, making its way along the road, while on the right side, a variety of parked cars add color and life to the urban landscape. As you continue to drive, you notice more details about the environment - a street vendor selling colorful items by the roadside, people walking their dogs, and the occasional cyclist navigating the busy lanes.\n",
      "\n",
      "The inside of your car reveals a comfortable setting with a modern dashboard featuring various controls and indicators. Your hands are firmly placed on the steering wheel, guiding the vehicle smoothly as you take in the sights and sounds of the city.\" \n",
      "\n",
      "Idx is 3, Time is 337.49484865507816. Action narration is \"You drive a car on the road.\".\n",
      "Detailed Description: \"As you drive a car on the road, your hands grip the steering wheel firmly. The dashboard is in clear view, with the speedometer and other gauges providing essential information about the vehicle's status. Outside, the road ahead stretches out, flanked by buildings of various colors and sizes. Other vehicles can be seen sharing the roadway, indicating that it is a busy time of day. As you navigate through this urban landscape, the sun casts bright light onto the pavement, creating sharp shadows from nearby structures. The windscreen offers an unobstructed view of the surroundings, allowing you to focus on the task at hand - driving safely and efficiently through the city streets.\" \n",
      "\n",
      "Idx is 4, Time is 363.10674865507815. Action narration is \"You look around.\".\n",
      "Detailed Description: \"As you look around, the interior of the car is revealed in detail. The dashboard features a variety of circular gauges and a digital display showing information such as speed and fuel level. On your left, the steering wheel prominently displays the brand logo at its center. Through the windshield, you can see a clear blue sky above and a tree-lined street ahead. As the vehicle moves forward, other cars come into view on the road, indicating traffic flow. On your right side, the side mirror reflects the changing scenery outside, including passing vehicles and roadside buildings.\" \n",
      "\n",
      "Idx is 5, Time is 364.91807865507815. Action narration is \"You drive a car on the road.\".\n",
      "Detailed Description: \"As you drive a car on the road, your hand firmly grips the steering wheel adorned with the brand's emblem. The dashboard in front of you is illuminated by the sunlight filtering through the windshield, casting a warm glow over the instrument cluster and center console. You can see various controls for the air conditioning and audio system, all within easy reach.\n",
      "\n",
      "The road ahead stretches out before you, lined with trees and occasional buildings. As you move forward, the scenery changes subtly, revealing more about the urban environment. Cars appear and pass by, and traffic signals guide your path. Reflections in the side mirror show the changing landscape as you navigate through the day.\n",
      "\n",
      "Inside the car, the driver's seat adjusts to ensure comfort, while the gear shifts indicate smooth transitions between lanes and stops. The rhythm of the journey continues, with the sounds of engines and distant city life forming a backdrop to this daily commute.\" \n",
      "\n",
      "Idx is 6, Time is 395.6524886550782. Action narration is \"You look around.\".\n",
      "Detailed Description: \"As you look around, the view shifts slightly from side to side. The dashboard of your car comes into clear focus, with its various dials and controls visible in detail. Through the windshield, a bright blue sky stretches out above, dotted with fluffy white clouds. Trees line the sides of the road, their leaves rustling gently in the breeze.\n",
      "\n",
      "In the distance, other vehicles can be seen on the road ahead, including a large red truck. To your right, there is a pedestrian crossing with a red sign indicating 'No Entry'. Further down the road, buildings and structures come into view, hinting at an urban environment. A person wearing a reflective vest stands near a construction site, overseeing work being done.\n",
      "\n",
      "The interior of your car remains consistent throughout, with sunlight streaming through the windows casting warm light inside. The steering wheel, with its emblem prominently displayed, guides your attention as you navigate the vehicle smoothly along the street.\" \n",
      "\n",
      "Idx is 7, Time is 397.5779186550782. Action narration is \"You drive on the road.\".\n",
      "Detailed Description: \"With your left hand firmly gripping the steering wheel, you drive on a well-paved road. The dashboard is in clear view, displaying various gauges and controls. As you navigate through the urban landscape, buildings of different architectural styles line both sides of the street. A mix of trees and greenery punctuates the concrete environment, adding a touch of nature to the cityscape.\n",
      "\n",
      "The car's interior is sleek and modern, with a focus on functionality and comfort. The windshield provides an unobstructed view of the road ahead, allowing for smooth navigation through traffic. You pass by other vehicles, including cars and trucks, as they move along the same route. Pedestrians can be seen walking along sidewalks or crossing streets at designated crossings, going about their daily routines.\n",
      "\n",
      "As you continue driving, the scenery shifts slightly but remains consistent with the urban setting. Occasionally, larger commercial buildings rise above smaller structures, showcasing the diversity of businesses within this bustling city. The bright sunlight casts sharp shadows across the road, highlighting the dynamic interplay between light and shadow in this vibrant metropolitan area.\" \n",
      "\n",
      "Idx is 8, Time is 404.76727865507814. Action narration is \"You stop the car.\".\n",
      "Detailed Description: \"As you stop the car, you feel a moment of stillness. The dashboard and steering wheel come into focus as your hands release their grip on the controls. Outside the windshield, you observe the traffic ahead, with several white cars waiting at what appears to be a red light. A building with \"next\" written in large letters stands out prominently on the left side of the frame, its facade reflecting the sunlight. To the right, greenery lines the sidewalk, adding a touch of nature to the urban setting. The interior of the car is bathed in natural light from the clear blue sky above, casting soft shadows inside the vehicle.\" \n",
      "\n",
      "Idx is 9, Time is 412.92064865507814. Action narration is \"You drive the car on the road.\".\n",
      "Detailed Description: \"As you drive the car on the road, your hands firmly grip the steering wheel, which bears a distinctive logo in its center. The dashboard is illuminated with various indicators and dials that provide essential information about the vehicle's status. Through the windshield, you observe a bustling urban environment filled with other cars, including white sedans and a BMW, navigating through traffic.\n",
      "\n",
      "The scene outside reveals a modern building with \"next\" written on it, indicating a shopping area nearby. As you move along the road, the lush greenery to the right contrasts with the concrete structures on the left. You can see pedestrians walking on the sidewalk, adding life to the cityscape. Traffic lights and street signs are visible at intervals, guiding the flow of vehicles.\n",
      "\n",
      "Throughout this journey, the sunlight casts dynamic shadows across the road, highlighting the movement and energy of the urban landscape. Despite the busy surroundings, the focus remains on the smooth operation of the car as you maneuver through the traffic, maintaining a steady pace and ensuring safe driving practices.\" \n",
      "\n",
      "Idx is 10, Time is 445.6686486550782. Action narration is \"You look around.\".\n",
      "Detailed Description: \"As you look around, the interior of your car comes into view. The dashboard is adorned with a variety of controls and displays, including the speedometer, fuel gauge, and temperature control knobs. The steering wheel prominently features the logo of the vehicle's brand. Outside the windshield, the urban landscape unfolds as you drive through the city streets.\n",
      "\n",
      "The road ahead is lined with traffic lights and pedestrian crossings, and buildings rise on either side, showcasing a mix of architectural styles from modern to historic. Other vehicles can be seen sharing the road, including cars in different colors and sizes. As you navigate the turns and straightaways, the scenery shifts slightly, revealing new elements such as street signs, trees, and occasional pedestrians.\n",
      "\n",
      "Throughout your journey, the sunlight casts shadows across the pavement, creating patterns that dance with the movement of the cars. The overall atmosphere is one of a typical day in an urban setting, filled with the hum of engines, the occasional honk of horns, and the soft murmur of conversations among the people going about their daily lives.\" \n",
      "\n",
      "Idx is 11, Time is 447.33752865507813. Action narration is \"You drive the car on the road.\".\n",
      "Detailed Description: \"With your hands firmly on the steering wheel, you carefully navigate the car along a bustling city street. The dashboard and various controls are visible in front of you, with the speedometer and other gauges clearly marked. As you drive forward, you pass by pedestrians walking on the sidewalks, colorful buildings lining the road, and lush green trees providing shade.\n",
      "\n",
      "The traffic flows steadily, with vehicles such as cars and trucks sharing the roadway. Occasionally, you slow down to allow other drivers to merge or change lanes safely. Traffic lights occasionally appear, guiding the flow of vehicles and ensuring orderly movement through intersections. The day is bright and sunny, casting shadows from the trees onto the pavement and highlighting the vibrant colors of the urban landscape.\n",
      "\n",
      "As you continue driving, you maintain a safe distance from other vehicles while staying alert to any changes in traffic patterns or road conditions. The sense of motion and the dynamic environment around you create an engaging experience, emphasizing the skill and focus required for safe driving in a busy city setting.\" \n",
      "\n",
      "Idx is 12, Time is 527.3505086550781. Action narration is \"You stop the car.\".\n",
      "Detailed Description: \"With a steady hand, you grip the steering wheel of your black car and gently press the brake pedal. The vehicle comes to a complete halt at the traffic light ahead, which is glowing red. As the car stops, you glance in the rearview mirror and see an orange cone placed on the road behind you, indicating some form of roadwork or obstruction.\n",
      "\n",
      "The dashboard of your car displays various illuminated indicators and dials, providing essential information about the vehicle's status and performance. Outside, through the windshield, you observe other vehicles, including a bright red SUV directly in front of you, patiently waiting for the signal to change. The scene is set against a backdrop of clear blue skies and lush greenery along the roadside, suggesting a pleasant day for driving.\" \n",
      "\n",
      "Idx is 13, Time is 533.8184286550782. Action narration is \"You look around.\".\n",
      "Detailed Description: \"As you look around, the interior of your vehicle is revealed. The dashboard houses a variety of gauges and dials that indicate various aspects of your car's performance. On the right side of the dashboard, there are air vents for climate control. You can see the steering wheel in front of you, which has several controls on it for ease of use while driving.\n",
      "\n",
      "Outside, through the windshield, you observe traffic ahead. A red car is directly in front of you at an intersection, waiting for the light to change. There are multiple traffic lights visible above the road, guiding vehicles safely. To the left, you notice greenery and trees lining the roadside, adding a touch of nature to the urban setting. In the distance, a clear blue sky stretches out, indicating good weather conditions.\n",
      "\n",
      "As the video progresses, you spot more elements within your environment. An orange traffic cone appears near the edge of the road, signaling potential roadwork or a temporary obstruction. Other cars come into view, navigating their way through the intersection. The scene remains dynamic as vehicles continue to move and interact with each other on the road.\" \n",
      "\n",
      "Idx is 14, Time is 556.7501986550782. Action narration is \"You drive a car on the road.\".\n",
      "Detailed Description: \"As you drive a car on the road, the dashboard in front of you is illuminated with various indicators and gauges. The steering wheel, adorned with controls for the vehicle's features, rests comfortably in your hands. Outside, the vibrant red car ahead of you contrasts against the clear blue sky. To your right, traffic signs and signals are visible, guiding the flow of vehicles. As you navigate through this dynamic environment, other cars appear in the periphery, reflecting the bustling nature of the road.\" \n",
      "\n",
      "\n",
      "{\n",
      "    \"0\": {\n",
      "        \"reason\": \"The caption describes various elements inside and outside the car but does not specifically mention a red car with a triangular sign or its movement relative to the vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"reason\": \"The caption mentions a maroon car with a warning triangle sticker and its movement, which is relevant to the visual cues specified in the question.\",\n",
      "        \"is_relational\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"reason\": \"The caption describes a red car with a triangular sign and its position relative to the vehicle, which directly relates to the visual cues needed for safe proceeding.\",\n",
      "        \"is_relational\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"reason\": \"The caption focuses on the interior of the car and a black Mercedes-Benz, but does not mention a red car with a triangular sign or its movement relative to the vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"reason\": \"The caption details the car's interior and street view but does not specifically mention a red car with a triangular sign or its movement relative to the vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"reason\": \"The caption describes the car's dashboard and driver's interactions but does not mention a red car with a triangular sign or its movement relative to the vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"6\": {\n",
      "        \"reason\": \"The caption mentions a red sedan in a parking lot but does not specify a triangular sign or its movement relative to the vehicle, which is crucial for the visual cues in question.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"7\": {\n",
      "        \"reason\": \"The caption details the car's interior and environment outside but does not specifically mention a red car with a triangular sign or its movement relative to the vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"8\": {\n",
      "        \"reason\": \"The caption describes the car's interior and surroundings but does not mention a red car with a triangular sign or its movement relative to the vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"9\": {\n",
      "        \"reason\": \"The caption provides a detailed description of the car's interior and surroundings but does not specifically mention a red car with a triangular sign or its movement relative to the vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"10\": {\n",
      "        \"reason\": \"The caption describes the car's interior and exterior components but does not mention any specific visual cues related to a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"11\": {\n",
      "        \"reason\": \"The caption mentions objects inside and outside the car, including traffic signs and other vehicles, but does not specifically reference a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"12\": {\n",
      "        \"reason\": \"This caption details the car's interior and exterior views, including traffic signs and other vehicles, but does not specifically mention a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"13\": {\n",
      "        \"reason\": \"The caption provides a detailed description of the car's interior and the surrounding urban landscape but does not specifically mention a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"14\": {\n",
      "        \"reason\": \"The caption describes the car's interior and the surrounding environment, including traffic lights and other vehicles, but does not specifically mention a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"15\": {\n",
      "        \"reason\": \"The caption mentions traffic lights and multiple cars of different colors but does not specifically reference a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"16\": {\n",
      "        \"reason\": \"The caption describes the car's interior and the traffic outside, including other vehicles and buildings, but does not specifically mention a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"17\": {\n",
      "        \"reason\": \"The caption provides a detailed first-person perspective of driving, including traffic lights and street signs, but does not specifically mention a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"18\": {\n",
      "        \"reason\": \"The caption describes various vehicles and traffic elements visible from the car, including a yellow construction truck and traffic signals, but does not specifically mention a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"19\": {\n",
      "        \"reason\": \"The caption lists objects visible to a driver, including traffic signs and other vehicles, but does not specifically mention a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"20\": {\n",
      "        \"reason\": \"The caption describes the interior of a car and the road ahead, including a traffic cone and a tunnel. However, it does not mention a red car with a triangular sign or its movement, which are the key visual cues for the question.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"21\": {\n",
      "        \"reason\": \"This caption mentions other cars and traffic cones but does not specifically describe a red car with a triangular sign or its movement relative to the viewer's vehicle.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"22\": {\n",
      "        \"reason\": \"The caption details the car's interior and exterior views, including other vehicles and traffic cones. However, it does not mention a red car with a triangular sign or its movement, which are crucial for the question.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"23\": {\n",
      "        \"reason\": \"This caption provides a detailed description of the car's interior and the road, including traffic cones and other vehicles. Yet, it lacks mention of a red car with a triangular sign or its specific movement, making it irrelevant to the question.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"24\": {\n",
      "        \"reason\": \"The caption describes the car's interior and the road ahead, including a white truck and guardrails. It does not mention a red car with a triangular sign or its movement, which are essential for the question.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"25\": {\n",
      "        \"reason\": \"This caption offers a comprehensive view of the car's interior and the surrounding environment, including other vehicles and traffic cones. However, it does not specifically mention a red car with a triangular sign or its movement, which are key to the question.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"26\": {\n",
      "        \"reason\": \"The caption mentions the driver's position, steering wheel, dashboard, traffic cone, and surrounding cars but does not specify a red car with a triangular sign or its movement, which are necessary for the question.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"27\": {\n",
      "        \"reason\": \"This caption describes a red car directly in front of the camera, traffic signals, and traffic cones. It aligns with the visual cues of a red car and its position, making it relevant to the question about proceeding safely.\",\n",
      "        \"is_relational\": true\n",
      "    },\n",
      "    \"28\": {\n",
      "        \"reason\": \"The caption details the car's interior and exterior, including a rearview mirror reflecting the road and other vehicles. However, it does not specifically mention a red car with a triangular sign or its movement, which are crucial for the question.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"29\": {\n",
      "        \"reason\": \"This caption lists various objects inside and outside the car, including other vehicles and road signs. However, it does not specifically mention a red car with a triangular sign or its movement, which are essential for the question.\",\n",
      "        \"is_relational\": false\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/zhangyl/videollm-online/dataset/move_action_function_v12_judge_v3_action/3d8f5230-0c22-4018-86b0-e6d851b74b11_56f7f97d-4be8-4778-8d0e-ab4811b75add_1_judege.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(merge_caption_with_action(all_caption, data, video_uid, clip_uid, video2scene, origin_narration))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,qa \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformqa(read_qa(video_uid, clip_uid, qas))):\n\u001b[0;32m----> 9\u001b[0m     judge \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvideo_uid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclip_uid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_judege.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(judge, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/videollm/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/zhangyl/videollm-online/dataset/move_action_function_v12_judge_v3_action/3d8f5230-0c22-4018-86b0-e6d851b74b11_56f7f97d-4be8-4778-8d0e-ab4811b75add_1_judege.json'"
     ]
    }
   ],
   "source": [
    "# for _ in range(0,1):\n",
    "print(video_uid, clip_uid)\n",
    "print(json.dumps(read_qa(video_uid, clip_uid, qas), indent=4))\n",
    "print(json.dumps(move_all_caption[video_uid][clip_uid],indent=4))\n",
    "print(merge_caption_with_action(all_caption, data, video_uid, clip_uid, video2scene, origin_narration))\n",
    "\n",
    "for i,qa in enumerate(transformqa(read_qa(video_uid, clip_uid, qas))):\n",
    "    \n",
    "    judge = json.load(open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_{i}_judege.json')))\n",
    "    print(json.dumps(judge, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/judge_relative_system_prompt_v2.txt').read()\n",
    "user_prompt = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/judge_relative_user_prompt.txt').read()\n",
    "caption_texts = merge_caption_wo_action(move_all_caption, video_uid, clip_uid, video2scene, origin_narration)\n",
    "with open('./tmp.txt', 'w') as f:\n",
    "    f.write(user_prompt.format(json.dumps(caption_texts,indent=4), json.dumps(qa, indent=4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "{\n",
      "    \"0\": {\n",
      "        \"caption\": \"The video presents a first-person perspective of navigating through various parts of an indoor environment, likely a small living space or apartment. Here is a detailed description of the objects and their positioning as observed:\\n\\n1. **Initial Scene (Top-left corner):**\\n   - A white ceiling with a window allowing natural light.\\n   - A coiled white cable hanging from the ceiling.\\n\\n2. **Backpack and Cleaning Supplies:**\\n   - A black backpack placed on a blue plastic storage bin.\\n   - Various cleaning supplies like brooms and mops in a green stand nearby.\\n\\n3. **Kitchen Area:**\\n   - White cabinets with golden handles.\\n   - A cluttered countertop with kitchen items including jars, bottles, and food packaging.\\n\\n4. **Refrigerator:**\\n   - Open refrigerator showing packed shelves with milk, juice cartons, bread, and other groceries.\\n\\n5. **Stove Area:**\\n   - Stove top with cooking utensils and containers around it.\\n   - A person's hand holding a box with nutritional information, suggesting they are reading labels.\\n\\n6. **Dishwasher and Sink Area:**\\n   - Dishwasher with clean dishes inside.\\n   - Sink area with a yellow sponge and other cleaning tools.\\n\\n7. **Storage Space:**\\n   - Cabinets and shelves filled with miscellaneous items such as food boxes, bottles, and household goods.\\n   - The camera pans to show different angles of the same storage areas, highlighting the cluttered nature of the space.\\n\\n8. **Person's Hand Interaction:**\\n   - A person's hand interacting with objects, such as opening a cabinet or picking up items from the counter.\\n\\n9. **Final Scenes:**\\n   - A view into a cardboard box containing a coffee maker.\\n   - Rapid movements blur the surroundings momentarily before focusing on a bright yellow object, possibly a toy, indicating quick transitions between scenes.\\n\\nThroughout the video, the observer moves and interacts with objects within this confined space, providing a dynamic yet intimate look at daily life activities within a compact living area. The camera work includes close-ups, panning shots, and rapid movements, reflecting a casual and spontaneous recording style.\",\n",
      "        \"reason\": \"The caption describes a detailed tour of an indoor environment, focusing on various areas like the kitchen, refrigerator, stove, and storage spaces. However, it does not specifically mention a fruit and vegetable display or any arrangement of produce in a store setting. The mention of a sink area is not sufficient to establish relevance to preparing vegetables in a store context.\",\n",
      "        \"is_relational\": false\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"caption\": \"The video begins with a blurred and shaky perspective, indicating rapid movement or instability. Initially, the scene is chaotic with various objects in disarray. A blue bucket, some yellow items, and other miscellaneous clutter are visible but details are obscured due to the blur.\\n\\nAs the camera moves, it captures more of the environment, revealing a kitchen setting. The counter is cluttered with numerous items including bottles, containers, and food packaging. There's a white refrigerator on one side, and cabinets above the counter. The floor appears to be wooden, and there's a mix of bright colors from the items scattered around.\\n\\nFurther movement reveals more of the room, showing additional objects like a microwave, a sink area, and more bottles and containers on the countertop. The camera continues to pan across the space, capturing different angles and perspectives of the kitchen.\\n\\nThroughout the clip, the camera's position shifts rapidly, leading to a dynamic view of the kitchen. Objects come into clearer focus as they move relative to the camera, while others remain out of focus due to the ongoing motion. Despite the lack of clear interaction between specific objects, the overall impression is of a busy, lived-in space with a variety of household items occupying the available surfaces.\\n\\nIn summary, the environment is a cluttered kitchen viewed from an unstable first-person perspective. Key elements include a variety of objects on countertops, a refrigerator, cabinets, and wooden flooring. The positioning and visibility of these objects change constantly due to the camera's movement, creating a sense of activity and disorganization within the space.\",\n",
      "        \"reason\": \"The caption describes a cluttered kitchen with various items and mentions a sink area, but it does not specifically describe a fruit and vegetable display or a similar arrangement of produce in a store setting. The focus is on the general disorganization and movement within the kitchen, not on preparing vegetables.\",\n",
      "        \"is_relational\": false\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/judge_relative_system_prompt_v2.txt').read()\n",
    "user_prompt = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/judge_relative_user_prompt.txt').read()\n",
    "caption_texts = merge_caption_wo_action(move_all_caption, video_uid, clip_uid, video2scene, origin_narration)\n",
    "for k,v in caption_texts.items():\n",
    "    question = user_prompt.format(json.dumps(v,indent=4), json.dumps(qa, indent=4))\n",
    "    answer = json.loads(get_llm_reponse_json(system_prompt, question))\n",
    "    caption_texts[k]['reason'] = answer['reason']\n",
    "    caption_texts[k]['is_relational'] = answer['is_relational']\n",
    "    \n",
    "print(json.dumps(caption_texts, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(caption_texts, open('./tmp1.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match success\n",
      "(269.99869786666665, 569.9653645333333)\n"
     ]
    }
   ],
   "source": [
    "def clipuid2cliptime(origin_narrations, video_uid, clip_uid):\n",
    "    summs = origin_narrations[video_uid]['summaries']\n",
    "    for summ in summs:\n",
    "        if summ['_annotation_uid'] == clip_uid:\n",
    "            print('match success')\n",
    "            break\n",
    "    clip_start_time = summ['start_time']\n",
    "    clip_end_time = summ['end_time']\n",
    "    return clip_start_time, clip_end_time\n",
    "\n",
    "print(clipuid2cliptime(origin_narration, video_uid, clip_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refine time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_json(json_data):\n",
    "    print(json.dumps(json_data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "qas = json.load(open('/home/zhangyl/videollm-online/data/estp/annotations/move_action_function_v7.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match success\n",
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Begin by organizing the countertop, which is cluttered with cleaning supplies, food containers, and utensils. Focus on the sink area, where dishes are piled up, and use the dish rack to the left for drying cleaned items.\",\n",
      "    \"time\": 935.69098125,\n",
      "    \"start_time\": 935.0733048026864,\n",
      "    \"end_time\": 936.3086576973137\n",
      "}\n",
      "{\n",
      "    \"Task Type\": \"Object Function\",\n",
      "    \"Question\": \"I need to clean up the kitchen. Where should I start?\",\n",
      "    \"conversation\": [\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"As you look around, the room reveals itself to be a cozy and lived-in space. The walls are painted in a soft, light color that reflects the natural light streaming in from an unseen window. To your right, there's a white refrigerator with various items placed on top of it, including a black appliance and some bottles. White cabinets line the wall above the counter, providing storage for kitchen essentials.\\n\\nThe counter is cluttered with everyday objects: a blue kettle sits near the sink, which has dishes piled up beside it waiting to be washed. A spray bottle, possibly containing cleaning solution, stands nearby along with other miscellaneous items like a red container and a green sponge holder. In front of the sink, a dish rack holds more utensils and cutlery, indicating recent use.\\n\\nIn the background, partially obscured by the clutter, is a small table or countertop with additional items scattered across its surface. Despite the disarray, the room exudes a sense of warmth and homeliness, hinting at the daily activities and routines that take place here.\",\n",
      "            \"content\": \"Begin by organizing the countertop, which is cluttered with cleaning supplies, food containers, and utensils. Focus on the sink area, where dishes are piled up, and use the dish rack to the left for drying cleaned items.\",\n",
      "            \"time\": 935.69098125,\n",
      "            \"start_time\": 935.0733048026864,\n",
      "            \"end_time\": 936.3086576973137\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"As you look around, your eyes take in the cluttered state of the kitchen. The white stove and its control panel are visible on the left side of the frame, with a digital clock displaying \\\"10:24\\\". On top of the stove, there's an array of items including bottles of various sizes, some with yellow caps, a black bag, and a red canister. To the right, a refrigerator stands against the wall, adorned with magnets and notes, one of which appears to be a reminder for milk.\\n\\nOn the counter, next to the stove, more items are scattered about, such as a carton of milk, a bottle of dish soap, and a container of what seems like cleaning supplies. There is also a blue plastic jug and a roll of paper towels. Among these objects, a red bowl rests on the stovetop, while a couple of other containers sit on the countertop beside it. The overall impression is that of a busy household kitchen, filled with everyday essentials and signs of recent activity.\",\n",
      "            \"content\": \"Begin by organizing the countertop, which is cluttered with cleaning supplies, food containers, and utensils. Focus on the sink area, where dishes are piled up, and use the dish rack to the left for drying cleaned items.\",\n",
      "            \"time\": 990.65184125,\n",
      "            \"start_time\": 990.0341648026863,\n",
      "            \"end_time\": 991.2695176973136\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"As you walk around the kitchen, you take in the various items and appliances. The white refrigerator stands tall on your left, its surface adorned with magnets and notes from family members. The countertops are cluttered with an assortment of dishes, a green dish soap bottle, and colorful sponges. On the right side of the room, a sink filled with dirty dishes is visible, indicating that meal preparation or cleanup has recently taken place. Above the sink, cabinets hang open, revealing more dishes and kitchen utensils. A window above the sink lets in natural light, illuminating the space and creating a warm atmosphere.\",\n",
      "            \"content\": \"Begin by organizing the countertop, which is cluttered with cleaning supplies, food containers, and utensils. Focus on the sink area, where dishes are piled up, and use the dish rack to the left for drying cleaned items.\",\n",
      "            \"time\": 1006.5656112500001,\n",
      "            \"start_time\": 1005.9479348026864,\n",
      "            \"end_time\": 1007.1832876973137\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"With your left hand, you hold a dish rack that is brimming with various dishes and utensils. The rack is positioned on the right side of the frame, and it's made of metal wire, showing signs of use with some spots of rust visible. You can see red plates stacked neatly on top of each other, alongside green plastic utensils. In the background, a white dishwasher is partially open, revealing its interior which has a blue and white geometric patterned door. As you adjust your grip, you notice how the items in the rack are organized for efficient cleaning.\",\n",
      "            \"content\": \"Begin by organizing the countertop, which is cluttered with cleaning supplies, food containers, and utensils. Focus on the sink area, where dishes are piled up, and use the dish rack to the left for drying cleaned items.\",\n",
      "            \"time\": 1021.02284125,\n",
      "            \"start_time\": 1020.4051648026864,\n",
      "            \"end_time\": 1021.6405176973137\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"As you look around, the cluttered kitchen environment becomes more apparent. The white stove in front of you is adorned with various items such as a brown pot on the back burner, a black kettle, and several containers including bottles of sauce and spices. To the right of the stove, there's a refrigerator partially visible, its door closed. Scattered across the countertops are numerous objects: milk cartons, a bottle of dish soap, bags of groceries, and other miscellaneous items. On the far left, part of a person can be seen, likely engaged in some activity near the sink or counter area. The lighting casts a warm glow over the entire scene, emphasizing the disarray and lived-in feel of the space.\",\n",
      "            \"content\": \"Begin by organizing the countertop, which is cluttered with cleaning supplies, food containers, and utensils. Focus on the sink area, where dishes are piled up, and use the dish rack to the left for drying cleaned items.\",\n",
      "            \"time\": 1047.07618125,\n",
      "            \"start_time\": 1046.4585048026863,\n",
      "            \"end_time\": 1047.6938576973137\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "match success\n",
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"The circular knob or button is located centrally on the white surface of the appliance. Move your hand towards it to adjust the settings or open the door.\",\n",
      "    \"time\": 1527.939955733333,\n",
      "    \"start_time\": 1527.6324376477148,\n",
      "    \"end_time\": 1528.247473818951\n",
      "}\n",
      "{\n",
      "    \"Task Type\": \"Object Function\",\n",
      "    \"Question\": \"I need to adjust the settings on my kitchen appliance. Where should I look?\",\n",
      "    \"conversation\": [\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"With a slight hesitation, you extend your right hand towards the gas stove burner. The burner is black with signs of use and residue, indicating it has been used frequently. As your fingers make contact, you feel its cool surface beneath your palm. You can see steam rising from the burner, hinting at its recent or current usage.\",\n",
      "            \"content\": \"The circular knob or button is located centrally on the white surface of the appliance. Move your hand towards it to adjust the settings or open the door.\",\n",
      "            \"time\": 1367.3322190666663,\n",
      "            \"start_time\": 1367.0247009810482,\n",
      "            \"end_time\": 1367.6397371522844\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"The video begins with a blurred close-up of what appears to be a white, curved surface, possibly part of a household appliance or furniture. The focus is initially indistinct, but as the camera moves slightly, it becomes clearer that this might be a section of a kitchen appliance, such as a dishwasher or refrigerator.\\n\\nAs the camera pans across the scene, a distinct circular knob or button becomes visible on the white surface. This object is centrally located and stands out against the background due to its round shape and contrasting color. There's no discernible movement in these frames; the only change is the camera's position relative to the objects, which reveals more details about their arrangement and design.\\n\\nIn subsequent frames, the camera continues to pan, bringing into view a human hand reaching towards the circular knob. The hand enters from the left side of the frame, suggesting an interaction between the observer and the appliance. The positioning of the hand indicates a potential action, such as turning the knob or opening a door.\\n\\nThroughout the clip, there are no significant changes in lighting or environment, maintaining a consistent indoor setting with neutral tones. The focus remains primarily on the interaction between the observer and the appliance, highlighting the significance of the circular knob within the context of the scene.\",\n",
      "            \"content\": \"The circular knob or button is located centrally on the white surface of the appliance. Move your hand towards it to adjust the settings or open the door.\",\n",
      "            \"time\": 1527.939955733333,\n",
      "            \"start_time\": 1527.3372202855214,\n",
      "            \"end_time\": 1528.5426911811444\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "match success\n",
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Begin with the cluttered countertop near the stove. Clear the containers, bottles, and food items to create space for organizing.\",\n",
      "    \"time\": 1364.2507390666663,\n",
      "    \"start_time\": 1363.8650262757603,\n",
      "    \"end_time\": 1364.6364518575722\n",
      "}\n",
      "{\n",
      "    \"Task Type\": \"Object Function\",\n",
      "    \"Question\": \"I need to clean up the kitchen. Where should I start?\",\n",
      "    \"conversation\": [\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"As you reach out, your hand gently touches the white surface of a gas cooker with four burners. The control knobs on the front are clearly visible, and you feel the smooth texture of the cookware placed on one of the burners. Nearby, various items such as a plastic bottle, a can, and some containers add to the cluttered appearance of the stove area.\",\n",
      "            \"content\": \"Begin with the cluttered countertop near the stove. Clear the containers, bottles, and food items to create space for organizing.\",\n",
      "            \"time\": 1368.2647590666663,\n",
      "            \"start_time\": 1367.8790462757604,\n",
      "            \"end_time\": 1368.6504718575723\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"With a quick and deliberate motion, you reach out to the cluttered countertop and pick up a white plastic bottle with a blue cap. The label is partially visible but difficult to read due to its position among other items. As you lift it, you notice that the bottle appears to be nearly empty, suggesting it might have been used recently for some household purpose.\",\n",
      "            \"content\": \"Begin with the cluttered countertop near the stove. Clear the containers, bottles, and food items to create space for organizing.\",\n",
      "            \"time\": 1410.5935790666663,\n",
      "            \"start_time\": 1410.2078662757604,\n",
      "            \"end_time\": 1410.9792918575722\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"As you walk into the kitchen, the sunlight streams in through a window on your left, casting a warm glow across the room. The walls are painted white, giving the space an airy and bright feel. You notice a wooden countertop with various items scattered across it, including a green cutting board, a knife block, and a few containers holding spices or condiments. On the floor, there's a blue exercise ball near the corner of the room, next to a small yellow cart filled with assorted items like boxes and bags. As you move forward, you pass by a black trash can situated close to the wall, and on its side lies a dirty plate covered in food residue. The overall atmosphere is cozy and lived-in, hinting at daily activities and personal touches within this domestic setting.\",\n",
      "            \"content\": \"Begin with the cluttered countertop near the stove. Clear the containers, bottles, and food items to create space for organizing.\",\n",
      "            \"time\": 1463.7065090666663,\n",
      "            \"start_time\": 1463.3207962757604,\n",
      "            \"end_time\": 1464.0922218575722\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"As you turn around, your gaze is drawn to a cluttered kitchen counter. The countertop, speckled with white and gray tones, hosts an array of items including two blue bottles, possibly containing dish soap or other cleaning agents. To the left, there's a bottle of peanut butter and a container of what appears to be a cooking spray. A yellow sponge rests near the sink, hinting at recent use. The faucet above the double basin gleams under the light, reflecting the shadows cast by various objects on the counter.\\n\\nAs you continue to survey the area, your eyes fall upon a small blue tray holding a few items, one of which seems to be a carton of eggs. Adjacent to this, a turquoise kettle sits atop the counter, its handle curving gracefully as it rests against a stack of plates. Nearby, a package of sliced cheese adds a splash of yellow to the otherwise muted color palette. Further exploration reveals more elements that add layers to the story of this lived-in space - a glimpse into daily life, captured in the stillness of these moments.\",\n",
      "            \"content\": \"Begin with the cluttered countertop near the stove. Clear the containers, bottles, and food items to create space for organizing.\",\n",
      "            \"time\": 1521.354745733333,\n",
      "            \"start_time\": 1520.969032942427,\n",
      "            \"end_time\": 1521.7404585242389\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"As you move into the kitchen, your eyes scan the room, taking in its cozy and lived-in atmosphere. The countertops are cluttered with various items: a purple vase sits near the sink, while a green container is nestled among an assortment of colorful bottles and jars on the right side. A bunch of ripe bananas rests on the counter, their bright yellow skins contrasting with the white surface. To the left, there's a black coffee maker, and nearby, a clear water bottle stands tall next to some snacks. As you walk further, the walls reveal a light cream color, and a window lets in natural light that illuminates the space. You notice a cabinet handle glinting in the sunlight as you approach it, indicating the presence of storage above the counter.\",\n",
      "            \"content\": \"Begin with the cluttered countertop near the stove. Clear the containers, bottles, and food items to create space for organizing.\",\n",
      "            \"time\": 1559.009515733333,\n",
      "            \"start_time\": 1558.6238029424271,\n",
      "            \"end_time\": 1559.395228524239\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"As you turn, the kitchen cabinet with a white finish and golden handles comes into view. Below it, a countertop is cluttered with various items including a purple bottle, an assortment of canned goods, a large water bottle, and a stack of bananas. On your right side, a blue bag hangs on the wall next to a green plant, adding a touch of nature to the scene. The sunlight streaming in from the window brightens up the space, casting soft shadows across the room.\",\n",
      "            \"content\": \"Begin with the cluttered countertop near the stove. Clear the containers, bottles, and food items to create space for organizing.\",\n",
      "            \"time\": 1580.474575733333,\n",
      "            \"start_time\": 1580.088862942427,\n",
      "            \"end_time\": 1580.860288524239\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"caption\": \"As you walk into the kitchen, your eyes are immediately drawn to a bright yellow stove with multiple burners. On top of it, there's a red pot and a black kettle. The countertops are cluttered with various items including a blue cutting board, a knife block, and several containers. To the right, there is a white refrigerator adorned with magnets and notes. As you move further in, you notice a sink filled with dishes and a window that lets in natural light, illuminating the room.\",\n",
      "            \"content\": \"Begin with the cluttered countertop near the stove. Clear the containers, bottles, and food items to create space for organizing.\",\n",
      "            \"time\": 1619.043575733333,\n",
      "            \"start_time\": 1618.657862942427,\n",
      "            \"end_time\": 1619.429288524239\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/zhangyl/videollm-online/dataset/move_action_function_v7_judge_v8_action/004a1802-c546-4dcc-86ba-bf1080077017_f99d9a39-f7ff-44f5-ae2c-6aa7036225f4_0_judege.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(output_dir_move_action):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_judege.json\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m         \u001b[43mrefine_qa_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[184], line 6\u001b[0m, in \u001b[0;36mrefine_qa_time\u001b[0;34m(qas, sample)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrefine_qa_time\u001b[39m(qas,sample):\n\u001b[0;32m----> 6\u001b[0m     action_judge \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msample\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m     move_action_judge \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir_move_action, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      9\u001b[0m     video_uid, clip_uid, qa_uid \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[:\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/videollm/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/zhangyl/videollm-online/dataset/move_action_function_v7_judge_v8_action/004a1802-c546-4dcc-86ba-bf1080077017_f99d9a39-f7ff-44f5-ae2c-6aa7036225f4_0_judege.json'"
     ]
    }
   ],
   "source": [
    "sample =  \"016bfe72-74ef-4956-9cc9-7a7ad2f6ab48_a194b487-aa15-4af2-8b0d-d01401aa145c_0\"\n",
    "output_dir_move_action = \"/home/zhangyl/videollm-online/dataset/move_action_function_v7_judge_v8\"\n",
    "output_dir_action = \"/home/zhangyl/videollm-online/dataset/move_action_function_v7_judge_v8_action\"\n",
    "\n",
    "def refine_qa_time(qas,sample):\n",
    "    action_judge = json.load(open(os.path.join(output_dir_action, f'{sample}.json')))\n",
    "    move_action_judge = json.load(open(os.path.join(output_dir_move_action, f'{sample}.json')))\n",
    "    \n",
    "    video_uid, clip_uid, qa_uid = sample.split('_')[:3]\n",
    "    start_time, end_time = clipuid2cliptime(origin_narration, video_uid, clip_uid)\n",
    "\n",
    "    qa = qas[video_uid][clip_uid][int(qa_uid)]\n",
    "\n",
    "    relative_caption = []\n",
    "    for k,v in action_judge.items():\n",
    "        if v['is_relational']:\n",
    "            relative_caption.append(all_caption[video_uid][clip_uid][int(k)])\n",
    "\n",
    "    for k,v in move_action_judge.items():\n",
    "        if v['is_relational']:\n",
    "            relative_caption.append(move_all_caption[video_uid][clip_uid][int(k)])\n",
    "\n",
    "    sorted_relative_caption = sorted(relative_caption, key=lambda x: x['time'])\n",
    "    print_json(qa['conversation'][0])\n",
    "    new_convsation = []\n",
    "    last_time = start_time\n",
    "    for cap in sorted_relative_caption:\n",
    "        if 'pre_scene' in cap.keys():\n",
    "            last_time = cap['end_time']\n",
    "            continue\n",
    "        if (cap['stamp_time'] - last_time) > 10:\n",
    "            new_convsation.append({\n",
    "                'role': 'assistant',\n",
    "                'caption': cap['caption'],\n",
    "                'content': qa['conversation'][0]['content'],\n",
    "                'time': cap['stamp_time'],\n",
    "                'start_time': cap['start_time'],\n",
    "                'end_time': cap['end_time'],\n",
    "            })\n",
    "            last_time = cap['time']\n",
    "    qa['conversation'] = new_convsation\n",
    "    print(json.dumps(qa, indent=4))\n",
    "    return\n",
    "\n",
    "for file in os.listdir(output_dir_move_action):\n",
    "    if file.endswith('_judege.json'):\n",
    "        refine_qa_time(qas, file.split('.')[0])\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"caption\": \"The video provides a first-person perspective of someone navigating through various areas within what appears to be a small, cluttered living space. The initial frames show the interior of a room with a ceiling fan and some items on the floor, including a blue storage box and a green chair or stool. As the camera moves, it reveals more details such as a white door with golden handles, a yellow shelf with assorted items like canned goods and cleaning supplies, and a window letting in natural light.\\n\\nThe focus then shifts to a kitchen area where the camera captures countertops filled with various objects including bottles, containers, and food items. The view transitions to include a stove top with a pot, indicating cooking activity. The surrounding environment is busy with scattered household items, suggesting a lived-in space with limited organization.\\n\\nSubsequent scenes reveal different parts of the house, including another angle of the kitchen showing a refrigerator stocked with groceries, a child's playroom with toys and a red tunnel, and a laundry or utility area with clothes and other miscellaneous items. The refrigerator is shown from an open perspective, displaying its contents clearly.\\n\\nThe video also includes views of a bathroom sink with personal hygiene products, a brief glimpse into a bedroom or living area with children's toys and a yellow toy car, and finally, a close-up of a sink with soaps and sponges, indicating routine activities such as cleaning.\\n\\nThroughout the video, the camera movement is dynamic, often panning across the room quickly, which makes object positions change rapidly relative to the observer. Some objects remain static while others are moved or interact with each other, such as when a hand reaches for items on the countertop or adjusts objects in the refrigerator.\\n\\nOverall, the video depicts a snapshot of daily life in a compact, possibly multi-purpose space with a variety of domestic activities occurring simultaneously, all viewed from a first-person perspective.\",\n",
      "        \"start_time\": 0,\n",
      "        \"end_time\": 1527.3372202855214,\n",
      "        \"pre_scene\": true,\n",
      "        \"text\": \"The video provides a first-person perspective of someone navigating through various areas within what appears to be a small, cluttered living space. The initial frames show the interior of a room with a ceiling fan and some items on the floor, including a blue storage box and a green chair or stool. As the camera moves, it reveals more details such as a white door with golden handles, a yellow shelf with assorted items like canned goods and cleaning supplies, and a window letting in natural light.\\n\\nThe focus then shifts to a kitchen area where the camera captures countertops filled with various objects including bottles, containers, and food items. The view transitions to include a stove top with a pot, indicating cooking activity. The surrounding environment is busy with scattered household items, suggesting a lived-in space with limited organization.\\n\\nSubsequent scenes reveal different parts of the house, including another angle of the kitchen showing a refrigerator stocked with groceries, a child's playroom with toys and a red tunnel, and a laundry or utility area with clothes and other miscellaneous items. The refrigerator is shown from an open perspective, displaying its contents clearly.\\n\\nThe video also includes views of a bathroom sink with personal hygiene products, a brief glimpse into a bedroom or living area with children's toys and a yellow toy car, and finally, a close-up of a sink with soaps and sponges, indicating routine activities such as cleaning.\\n\\nThroughout the video, the camera movement is dynamic, often panning across the room quickly, which makes object positions change rapidly relative to the observer. Some objects remain static while others are moved or interact with each other, such as when a hand reaches for items on the countertop or adjusts objects in the refrigerator.\\n\\nOverall, the video depicts a snapshot of daily life in a compact, possibly multi-purpose space with a variety of domestic activities occurring simultaneously, all viewed from a first-person perspective.\",\n",
      "        \"time\": 1527.3372202855214\n",
      "    },\n",
      "    {\n",
      "        \"caption\": \"The video begins with a blurred close-up of what appears to be a white, curved surface, possibly part of a household appliance or furniture. The focus is initially indistinct, but as the camera moves slightly, it becomes clearer that this might be a section of a kitchen appliance, such as a dishwasher or refrigerator.\\n\\nAs the camera pans across the scene, a distinct circular knob or button becomes visible on the white surface. This object is centrally located and stands out against the background due to its round shape and contrasting color. There's no discernible movement in these frames; the only change is the camera's position relative to the objects, which reveals more details about their arrangement and design.\\n\\nIn subsequent frames, the camera continues to pan, bringing into view a human hand reaching towards the circular knob. The hand enters from the left side of the frame, suggesting an interaction between the observer and the appliance. The positioning of the hand indicates a potential action, such as turning the knob or opening a door.\\n\\nThroughout the clip, there are no significant changes in lighting or environment, maintaining a consistent indoor setting with neutral tones. The focus remains primarily on the interaction between the observer and the appliance, highlighting the significance of the circular knob within the context of the scene.\",\n",
      "        \"stamp_time\": 1527.939955733333,\n",
      "        \"start_time\": 1527.3372202855214,\n",
      "        \"end_time\": 1528.5426911811444,\n",
      "        \"simi\": 0.725548505783081,\n",
      "        \"action_narration\": \"You adjust the camera on your head with both hands.\",\n",
      "        \"action_idx\": 60,\n",
      "        \"text\": \"The video begins with a blurred close-up of what appears to be a white, curved surface, possibly part of a household appliance or furniture. The focus is initially indistinct, but as the camera moves slightly, it becomes clearer that this might be a section of a kitchen appliance, such as a dishwasher or refrigerator.\\n\\nAs the camera pans across the scene, a distinct circular knob or button becomes visible on the white surface. This object is centrally located and stands out against the background due to its round shape and contrasting color. There's no discernible movement in these frames; the only change is the camera's position relative to the objects, which reveals more details about their arrangement and design.\\n\\nIn subsequent frames, the camera continues to pan, bringing into view a human hand reaching towards the circular knob. The hand enters from the left side of the frame, suggesting an interaction between the observer and the appliance. The positioning of the hand indicates a potential action, such as turning the knob or opening a door.\\n\\nThroughout the clip, there are no significant changes in lighting or environment, maintaining a consistent indoor setting with neutral tones. The focus remains primarily on the interaction between the observer and the appliance, highlighting the significance of the circular knob within the context of the scene.\",\n",
      "        \"time\": 1528.5426911811444\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print_json(move_all_caption[video_uid][clip_uid])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videollm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
