{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyl/miniconda3/envs/videollm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "EGO_ROOT = '/home/zhangyl/videollm-online/datasets/ego4d/'\n",
    "CAPTION_ROOT = '/home/zhangyl/videollm-online/datasets/ego4d_action_caption/train_0_merge'\n",
    "MOVE_CAPTION_ROOT = '/home/zhangyl/videollm-online/datasets/ego4d_move_action_caption/train_0_merge'\n",
    "\n",
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from video_caption_action_scene import AnnotationLoader, BetaAlphaCalculator\n",
    "\n",
    "EGO_VERSION_ROOT = os.path.join(EGO_ROOT, 'v2')\n",
    "json_path = os.path.join(EGO_ROOT, 'ego4d.json')\n",
    "train_path = f'{EGO_VERSION_ROOT}/annotations/refined_narration_stream_train.json'\n",
    "val_path = f'{EGO_VERSION_ROOT}/annotations/refined_narration_stream_val.json'\n",
    "origin_path = f'{EGO_VERSION_ROOT}/annotations/all_narrations_redacted.json'\n",
    "video_root = f'{EGO_VERSION_ROOT}/full_scale_2fps'\n",
    "alpha = 4.9\n",
    "device = 'cuda:3'\n",
    "caption_dir = '/root/videollm-online/tmp5'\n",
    "\n",
    "annotation_loader = AnnotationLoader(train_path, val_path, origin_path, json_path)\n",
    "data = annotation_loader.get_data()\n",
    "origin_narration = annotation_loader.get_origin_narration()\n",
    "\n",
    "beta_alpha_calculator = BetaAlphaCalculator(data, alpha)\n",
    "beta_alpha_calculator.compute_beta()\n",
    "beta_map = beta_alpha_calculator.get_beta_map()\n",
    "alpha = beta_alpha_calculator.get_alpha()\n",
    "\n",
    "train_caption = json.load(open(f'{CAPTION_ROOT}/action_caption_train.json'))\n",
    "val_caption = json.load(open(f'{CAPTION_ROOT}/action_caption_val.json'))\n",
    "all_caption = {**train_caption, **val_caption}\n",
    "\n",
    "move_train_caption = json.load(open(f'{MOVE_CAPTION_ROOT}/action_caption_train.json'))\n",
    "move_val_caption = json.load(open(f'{MOVE_CAPTION_ROOT}/action_caption_val.json'))\n",
    "move_all_caption = {**move_train_caption, **move_val_caption}\n",
    "video2scene = json.load(open('/home/zhangyl/videollm-online/data/estp/ego4d/metafile/video2scene.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# object QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## action merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_caption_with_action(captions, narrations, video_uid, clip_uid, video2scene, origin_narration):\n",
    "    narration = narrations[video_uid][clip_uid]\n",
    "    caption = captions[video_uid][clip_uid]\n",
    "    \n",
    "    caption_texts = \"\"\n",
    "    for action_idx, (nar, cap) in enumerate(zip(narration, caption)):\n",
    "        action_narration = 'Time is {}. Action narration is \\\"'.format(nar['time']) + nar['text'] + '\\\".\\n'\n",
    "        caption_text = 'Detailed Description: \\\"' + cap['text'] + '\\\" \\n'\n",
    "        caption_text = action_narration + caption_text\n",
    "        caption_texts += caption_text + '\\n'\n",
    "        \n",
    "    return caption_texts\n",
    "\n",
    "def caption_merger_waction(captions, video2scene, origin_narration):\n",
    "    for video_uid in captions.keys():\n",
    "        for clip_uid in captions[video_uid].keys():\n",
    "            caption_texts = merge_caption_with_action(captions, data, video_uid, clip_uid, video2scene, origin_narration)\n",
    "            yield caption_texts, video_uid, clip_uid\n",
    "\n",
    "caption_merger2 = caption_merger_waction(all_caption, video2scene, origin_narration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is 270.0. Action narration is \"You fold the luggage.\".\n",
      "Detailed Description: \"With a sense of purpose, you begin to fold the luggage. The beige fabric of the suitcase is well-worn but still sturdy as it sits on the floor in front of you. You methodically work through the steps: first, you gather the edges and bring them together, then you tuck in the straps, ensuring they are neatly tucked away. As you continue, the once sprawling mass of fabric gradually transforms into a compact, manageable size, ready for transport or storage.\" \n",
      "\n",
      "Time is 301.29231. Action narration is \"You look around.\".\n",
      "Detailed Description: \"As you look around, the room appears dimly lit with a warm, yellowish hue. The walls are painted in a light beige color, and there's a noticeable shadow cast by an unseen object or person. In front of you, on the floor, lies a large, brown blanket that seems to be spread out, possibly covering something underneath. To your right, part of a white furry pet is visible, its fur appearing soft and fluffy. On the far left side of the frame, a portion of a blue long-sleeved shirt can be seen worn by someone sitting down, their face obscured from view.\" \n",
      "\n",
      "Time is 365.99135. Action narration is \"She bags the bag.\".\n",
      "Detailed Description: \"As she bends down, her hand reaches into the white plastic bag. She meticulously sorts through its contents, picking out items and placing them neatly inside a brown paper bag. The room is dimly lit, casting soft shadows around her as she works diligently to organize the belongings in the bags.\" \n",
      "\n",
      "Time is 374.55773. Action narration is \"You lift the luggage and put it in the bag.\".\n",
      "Detailed Description: \"With a firm grip, you lift the large brown suitcase from the ground. You carefully position it on top of your beige shoulder bag, making sure that both items are securely placed and balanced for easy transport.\" \n",
      "\n",
      "Time is 412.69225. Action narration is \"She closes the bag zip.\".\n",
      "Detailed Description: \"With her right hand, she reaches for the beige bag that rests on her lap. She gently pulls at the zipper with a sense of purpose and care, ensuring it is securely fastened. The zipper glides smoothly over the fabric, and as she completes the action, she turns to face forward, her attention momentarily diverted from the task at hand.\" \n",
      "\n",
      "Time is 467.87971. Action narration is \"You lift the bag of luggage.\".\n",
      "Detailed Description: \"With a gentle yet firm grip, you lift the white bag of luggage from its resting place on the floor. The fabric of the bag appears slightly crinkled due to the weight it carries. As you hoist the bag, you notice that it is quite full, suggesting it contains various items for travel or storage.\" \n",
      "\n",
      "Time is 469.82164. Action narration is \"You give the bag of luggage to her.\".\n",
      "Detailed Description: \"With a gentle smile, you extend your hand towards the woman standing in front of you. The bag of luggage is securely held in your grasp. As you give it to her, she takes it with both hands and examines its contents before adjusting her grip. Her expression is one of gratitude and satisfaction as she prepares to transport the luggage elsewhere.\" \n",
      "\n",
      "Time is 470.75335. Action narration is \"She lifts the luggage.\".\n",
      "Detailed Description: \"With a determined expression, she approaches the large beige suitcase standing upright in the center of the room. Her hands grip the handle firmly and with practiced ease, she lifts it off the ground. The suitcase, sturdy and well-worn from frequent travels, responds to her strength as she maneuvers it across the tiled floor towards the open doorway leading outside.\" \n",
      "\n",
      "Time is 477.92945. Action narration is \"She gives back the luggage to you.\".\n",
      "Detailed Description: \"As you approach the woman, she hands over a large, light-colored luggage bag to you. The bag appears sturdy and spacious, suitable for travel. You take it from her with both hands, expressing gratitude as you hold it securely in front of you.\" \n",
      "\n",
      "Time is 479.61994000000004. Action narration is \"You carry the luggage.\".\n",
      "Detailed Description: \"As you carry the luggage, your left hand gently grasps its handle, supporting it as you walk. The suitcase is a medium-sized, dark-colored hard-shell with visible signs of wear and tear from frequent use. You move across the room, passing by various objects like a small black bag on the floor to your right and a white plastic chair in front of you. As you progress, the walls around you are adorned with framed pictures, adding a personal touch to the space. In the background, another person can be seen standing near an open doorway, observing your movements.\" \n",
      "\n",
      "Time is 481.93093999999996. Action narration is \"You move around.\".\n",
      "Detailed Description: \"As you move around, the room's layout becomes more apparent. The beige floor stretches out in front of you, leading to a set of black-framed glass doors that are slightly ajar. Through these doors, you can see another room with various objects scattered about, including what appears to be a white chair and some items on a table. To your right, there is a metal vent, suggesting an air conditioning or heating system. You notice a piece of paper lying on the floor near the door, and as you walk closer, you reach out and open the door fully.\" \n",
      "\n",
      "Time is 483.34427. Action narration is \"You close the door.\".\n",
      "Detailed Description: \"With a sense of purpose, you reach out and close the door gently. The metallic handle clicks into place as the door slides shut, sealing off the room from the outside world. As the door closes, the interior space becomes more intimate, with the sound of the door latch becoming muffled in the enclosed environment. You take a moment to assess your surroundings, taking in the details that make up this personal sanctuary.\" \n",
      "\n",
      "Time is 489.37571. Action narration is \"You get out of the house.\".\n",
      "Detailed Description: \"With a sense of urgency, you quickly move towards the front door, grabbing your keys from the side table as you go. You open the door and step outside, closing it behind you with a decisive click. The cool night air hits your face, and you take a deep breath before beginning to walk down the dimly lit street.\" \n",
      "\n",
      "Time is 496.77753. Action narration is \"You move along the street.\".\n",
      "Detailed Description: \"As you move along the street, the darkness of the night envelops you. The only sources of light come from the distant buildings and a few scattered street lamps that cast a soft glow on the pavement. You walk with purpose, your feet brushing against the cool surface as you navigate through the quiet streets. The occasional car headlights streak by in the distance, their bright beams cutting through the shadows. The air is crisp and cool, suggesting it might be late autumn or early winter. Your breath is visible in the cold night air, adding to the sense of movement and life amidst the stillness.\" \n",
      "\n",
      "Time is 560.7288293333332. Action narration is \"You enter the house.\".\n",
      "Detailed Description: \"With a sense of anticipation, you step into the house. The threshold beneath your feet creaks slightly as you transition from the outdoors to the indoor environment. The interior is warmly lit, casting a cozy glow on the tiled floor and the surrounding walls. To your right, a tall black pillar stands prominently against the backdrop of a dark wall with horizontal slats. Potted plants are neatly arranged along the base of this pillar, their green leaves contrasting with the muted tones of the architecture. As you move forward, the sound of footsteps echoes softly in the quiet space, adding to the atmosphere of entering a private sanctuary.\" \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(next(caption_merger2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'caption_merger2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m user_prompt_templete_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/zhangyl/videollm-online/data/estp/ego4d/prompt/action_caption2a_prompt.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     caption_texts, video_uid, clip_uid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mcaption_merger2\u001b[49m)\n\u001b[1;32m     35\u001b[0m     user_prompt \u001b[38;5;241m=\u001b[39m user_prompt_templete\u001b[38;5;241m.\u001b[39mformat(caption_texts)\n\u001b[1;32m     36\u001b[0m     question \u001b[38;5;241m=\u001b[39m get_llm_response_json(system_prompt, user_prompt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'caption_merger2' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def get_llm_response_json(system_prompt, user_prompt):\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=\"\",\n",
    "        base_url=\"https://api.deepseek.com\",\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "system_prompt = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/action_caption2q_system.txt').read().format(NUMBER=3)\n",
    "user_prompt_templete = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/action_caption2q_prompt.txt').read()\n",
    "output_dir = '/home/zhangyl/videollm-online/dataset/action/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "system_prompt_a = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/action_caption2a_system.txt').read()\n",
    "user_prompt_templete_a = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/action_caption2a_prompt.txt').read()\n",
    "\n",
    "for i in range(0,10):\n",
    "\n",
    "    caption_texts, video_uid, clip_uid = next(caption_merger2)\n",
    "\n",
    "    user_prompt = user_prompt_templete.format(caption_texts)\n",
    "    question = get_llm_response_json(system_prompt, user_prompt)\n",
    "    \n",
    "    user_prompt = user_prompt_templete_a.format(caption_texts, question)\n",
    "    answer = get_llm_response_json(system_prompt_a, user_prompt)\n",
    "\n",
    "    with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_caption.txt'), 'w') as f:\n",
    "        f.write(user_prompt)\n",
    "    with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_q.txt'), 'w') as f:\n",
    "        f.write(question)\n",
    "    with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_a.txt'), 'w') as f:\n",
    "        f.write(answer)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## move action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_caption_wo_action(captions, video_uid, clip_uid, video2scene, origin_narration, w_pre = False):\n",
    "    caption = captions[video_uid][clip_uid]\n",
    "    \n",
    "    caption_texts = \"\"\n",
    "    for action_idx, cap in enumerate(caption):\n",
    "        \n",
    "        if 'stamp_time' not in cap and w_pre:\n",
    "            action_narration = 'Time is {} - {}.\\n'.format(cap['start_time'], cap['end_time'])\n",
    "        elif 'stamp_time' not in cap and not w_pre:\n",
    "            continue\n",
    "        else:\n",
    "            action_narration = 'Time is {}.\\n'.format(cap['stamp_time'])\n",
    "        caption_text = 'Detailed Description: \\\"' + cap['text'] + '\\\".\\n'\n",
    "        caption_text = action_narration + caption_text\n",
    "        caption_texts += caption_text + '\\n\\n'\n",
    "        \n",
    "    return caption_texts\n",
    "\n",
    "def caption_merger(captions, video2scene, origin_narration, w_pre = False):\n",
    "    for video_uid in captions.keys():\n",
    "        for clip_uid in captions[video_uid].keys():\n",
    "            caption_texts = merge_caption_wo_action(captions, video_uid, clip_uid, video2scene, origin_narration, w_pre = False)\n",
    "            yield caption_texts, video_uid, clip_uid\n",
    "\n",
    "caption_merger1 = caption_merger(move_all_caption, video2scene, origin_narration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def get_llm_response_json(system_prompt, user_prompt):\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=\"\",\n",
    "        base_url=\"https://api.deepseek.com\",\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "system_prompt = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/caption2qa_system.txt').read().format(NUMBER=2)\n",
    "user_prompt_templete = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/caption2qa_prompt.txt').read()\n",
    "output_dir = '/home/zhangyl/videollm-online/dataset/move_action_v21/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "system_prompt_a = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/action_caption2a_system.txt').read()\n",
    "user_prompt_templete_a = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/action_caption2a_prompt.txt').read()\n",
    "\n",
    "for i in range(0,10):\n",
    "\n",
    "    caption_texts, video_uid, clip_uid = next(caption_merger1)\n",
    "\n",
    "    user_prompt = user_prompt_templete.format(caption_texts)\n",
    "    answer = get_llm_response_json(system_prompt, user_prompt)\n",
    "\n",
    "    with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_caption.txt'), 'w') as f:\n",
    "        f.write(user_prompt)\n",
    "    with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_qa.txt'), 'w') as f:\n",
    "        f.write(answer)\n",
    "    \n",
    "    # user_prompt = user_prompt_templete_a.format(caption_texts, answer)\n",
    "    # answer = get_llm_response_json(system_prompt_a, user_prompt)\n",
    "    \n",
    "    # with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_caption2.txt'), 'w') as f:\n",
    "    #     f.write(user_prompt)\n",
    "    # with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_a.txt'), 'w') as f:\n",
    "    #     f.write(answer)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## move action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_caption_wo_action(captions, video_uid, clip_uid, video2scene, origin_narration, w_pre = False):\n",
    "    caption = captions[video_uid][clip_uid]\n",
    "    \n",
    "    caption_texts = \"Video Subject : {}\\n\".format(' / '.join(video2scene[video_uid]))\n",
    "    for action_idx, cap in enumerate(caption):\n",
    "        \n",
    "        if 'stamp_time' not in cap and w_pre:\n",
    "            action_narration = 'Time is {} - {}.\\n'.format(cap['start_time'], cap['end_time'])\n",
    "        elif 'stamp_time' not in cap and not w_pre:\n",
    "            continue\n",
    "        else:\n",
    "            action_narration = 'Time is {}.\\n'.format(cap['stamp_time'])\n",
    "        caption_text = 'Detailed Description: \\\"' + cap['text'] + '\\\".\\n'\n",
    "        caption_text = action_narration + caption_text\n",
    "        caption_texts += caption_text + '\\n\\n'\n",
    "        \n",
    "    return caption_texts\n",
    "\n",
    "def caption_merger(captions, video2scene, origin_narration):\n",
    "    for video_uid in captions.keys():\n",
    "        for clip_uid in captions[video_uid].keys():\n",
    "            caption_texts = merge_caption_wo_action(captions, video_uid, clip_uid, video2scene, origin_narration)\n",
    "            yield caption_texts, video_uid, clip_uid\n",
    "\n",
    "caption_merger1 = caption_merger(move_all_caption, video2scene, origin_narration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def get_llm_response_json(system_prompt, user_prompt):\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=\"\",\n",
    "        base_url=\"https://api.deepseek.com\",\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-reasoner\", # deepseek-reasoner deepseek-chat\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "system_prompt = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/caption2qa_function_system.txt').read().format(NUMBER=2)\n",
    "user_prompt_templete = open('/home/zhangyl/videollm-online/data/estp/ego4d/prompt/caption2qa_function_prompt.txt').read()\n",
    "output_dir = '/home/zhangyl/videollm-online/dataset/move_action_function_v1_reason/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for _ in range(0,10):\n",
    "    \n",
    "    caption_texts, video_uid, clip_uid = next(caption_merger1)\n",
    "    user_prompt = user_prompt_templete.format(caption_texts)\n",
    "    answer = get_llm_response_json(system_prompt, user_prompt)\n",
    "\n",
    "    with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_caption.txt'), 'w') as f:\n",
    "        f.write(user_prompt)\n",
    "    with open(os.path.join(output_dir, f'{video_uid}_{clip_uid}_qa.txt'), 'w') as f:\n",
    "        f.write(answer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_caption_with_action(captions, narrations, video_uid, clip_uid, video2scene, origin_narration):\n",
    "    narration = narrations[video_uid][clip_uid]\n",
    "    caption = captions[video_uid][clip_uid]\n",
    "    \n",
    "    caption_texts = \"Video Subject : {}\\n\".format(' / '.join(video2scene[video_uid]))\n",
    "    for action_idx, (nar, cap) in enumerate(zip(narration, caption)):\n",
    "        action_narration = 'Time is {}. Action narration is \\\"'.format(nar['time']) + nar['text'] + '\\\".\\n'\n",
    "        caption_text = 'Detailed Description: \\\"' + cap['text'] + '\\\" \\n'\n",
    "        caption_text = action_narration + caption_text\n",
    "        caption_texts += caption_text + '\\n'\n",
    "        \n",
    "    return caption_texts\n",
    "\n",
    "def caption_merger_waction(captions, video2scene, origin_narration):\n",
    "    for video_uid in captions.keys():\n",
    "        for clip_uid in captions[video_uid].keys():\n",
    "            caption_texts = merge_caption_with_action(captions, data, video_uid, clip_uid, video2scene, origin_narration)\n",
    "            yield caption_texts, video_uid, clip_uid\n",
    "\n",
    "caption_merger2 = caption_merger_waction(all_caption, video2scene, origin_narration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Subject : BBQ'ing/picnics / Walking on street\n",
      "Time is 270.0. Action narration is \"You fold the luggage.\".\n",
      "Detailed Description: \"With a sense of purpose, you begin to fold the luggage. The beige fabric of the suitcase is well-worn but still sturdy as it sits on the floor in front of you. You methodically work through the steps: first, you gather the edges and bring them together, then you tuck in the straps, ensuring they are neatly tucked away. As you continue, the once sprawling mass of fabric gradually transforms into a compact, manageable size, ready for transport or storage.\" \n",
      "\n",
      "Time is 301.29231. Action narration is \"You look around.\".\n",
      "Detailed Description: \"As you look around, the room appears dimly lit with a warm, yellowish hue. The walls are painted in a light beige color, and there's a noticeable shadow cast by an unseen object or person. In front of you, on the floor, lies a large, brown blanket that seems to be spread out, possibly covering something underneath. To your right, part of a white furry pet is visible, its fur appearing soft and fluffy. On the far left side of the frame, a portion of a blue long-sleeved shirt can be seen worn by someone sitting down, their face obscured from view.\" \n",
      "\n",
      "Time is 365.99135. Action narration is \"She bags the bag.\".\n",
      "Detailed Description: \"As she bends down, her hand reaches into the white plastic bag. She meticulously sorts through its contents, picking out items and placing them neatly inside a brown paper bag. The room is dimly lit, casting soft shadows around her as she works diligently to organize the belongings in the bags.\" \n",
      "\n",
      "Time is 374.55773. Action narration is \"You lift the luggage and put it in the bag.\".\n",
      "Detailed Description: \"With a firm grip, you lift the large brown suitcase from the ground. You carefully position it on top of your beige shoulder bag, making sure that both items are securely placed and balanced for easy transport.\" \n",
      "\n",
      "Time is 412.69225. Action narration is \"She closes the bag zip.\".\n",
      "Detailed Description: \"With her right hand, she reaches for the beige bag that rests on her lap. She gently pulls at the zipper with a sense of purpose and care, ensuring it is securely fastened. The zipper glides smoothly over the fabric, and as she completes the action, she turns to face forward, her attention momentarily diverted from the task at hand.\" \n",
      "\n",
      "Time is 467.87971. Action narration is \"You lift the bag of luggage.\".\n",
      "Detailed Description: \"With a gentle yet firm grip, you lift the white bag of luggage from its resting place on the floor. The fabric of the bag appears slightly crinkled due to the weight it carries. As you hoist the bag, you notice that it is quite full, suggesting it contains various items for travel or storage.\" \n",
      "\n",
      "Time is 469.82164. Action narration is \"You give the bag of luggage to her.\".\n",
      "Detailed Description: \"With a gentle smile, you extend your hand towards the woman standing in front of you. The bag of luggage is securely held in your grasp. As you give it to her, she takes it with both hands and examines its contents before adjusting her grip. Her expression is one of gratitude and satisfaction as she prepares to transport the luggage elsewhere.\" \n",
      "\n",
      "Time is 470.75335. Action narration is \"She lifts the luggage.\".\n",
      "Detailed Description: \"With a determined expression, she approaches the large beige suitcase standing upright in the center of the room. Her hands grip the handle firmly and with practiced ease, she lifts it off the ground. The suitcase, sturdy and well-worn from frequent travels, responds to her strength as she maneuvers it across the tiled floor towards the open doorway leading outside.\" \n",
      "\n",
      "Time is 477.92945. Action narration is \"She gives back the luggage to you.\".\n",
      "Detailed Description: \"As you approach the woman, she hands over a large, light-colored luggage bag to you. The bag appears sturdy and spacious, suitable for travel. You take it from her with both hands, expressing gratitude as you hold it securely in front of you.\" \n",
      "\n",
      "Time is 479.61994000000004. Action narration is \"You carry the luggage.\".\n",
      "Detailed Description: \"As you carry the luggage, your left hand gently grasps its handle, supporting it as you walk. The suitcase is a medium-sized, dark-colored hard-shell with visible signs of wear and tear from frequent use. You move across the room, passing by various objects like a small black bag on the floor to your right and a white plastic chair in front of you. As you progress, the walls around you are adorned with framed pictures, adding a personal touch to the space. In the background, another person can be seen standing near an open doorway, observing your movements.\" \n",
      "\n",
      "Time is 481.93093999999996. Action narration is \"You move around.\".\n",
      "Detailed Description: \"As you move around, the room's layout becomes more apparent. The beige floor stretches out in front of you, leading to a set of black-framed glass doors that are slightly ajar. Through these doors, you can see another room with various objects scattered about, including what appears to be a white chair and some items on a table. To your right, there is a metal vent, suggesting an air conditioning or heating system. You notice a piece of paper lying on the floor near the door, and as you walk closer, you reach out and open the door fully.\" \n",
      "\n",
      "Time is 483.34427. Action narration is \"You close the door.\".\n",
      "Detailed Description: \"With a sense of purpose, you reach out and close the door gently. The metallic handle clicks into place as the door slides shut, sealing off the room from the outside world. As the door closes, the interior space becomes more intimate, with the sound of the door latch becoming muffled in the enclosed environment. You take a moment to assess your surroundings, taking in the details that make up this personal sanctuary.\" \n",
      "\n",
      "Time is 489.37571. Action narration is \"You get out of the house.\".\n",
      "Detailed Description: \"With a sense of urgency, you quickly move towards the front door, grabbing your keys from the side table as you go. You open the door and step outside, closing it behind you with a decisive click. The cool night air hits your face, and you take a deep breath before beginning to walk down the dimly lit street.\" \n",
      "\n",
      "Time is 496.77753. Action narration is \"You move along the street.\".\n",
      "Detailed Description: \"As you move along the street, the darkness of the night envelops you. The only sources of light come from the distant buildings and a few scattered street lamps that cast a soft glow on the pavement. You walk with purpose, your feet brushing against the cool surface as you navigate through the quiet streets. The occasional car headlights streak by in the distance, their bright beams cutting through the shadows. The air is crisp and cool, suggesting it might be late autumn or early winter. Your breath is visible in the cold night air, adding to the sense of movement and life amidst the stillness.\" \n",
      "\n",
      "Time is 560.7288293333332. Action narration is \"You enter the house.\".\n",
      "Detailed Description: \"With a sense of anticipation, you step into the house. The threshold beneath your feet creaks slightly as you transition from the outdoors to the indoor environment. The interior is warmly lit, casting a cozy glow on the tiled floor and the surrounding walls. To your right, a tall black pillar stands prominently against the backdrop of a dark wall with horizontal slats. Potted plants are neatly arranged along the base of this pillar, their green leaves contrasting with the muted tones of the architecture. As you move forward, the sound of footsteps echoes softly in the quiet space, adding to the atmosphere of entering a private sanctuary.\" \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(next(caption_merger2)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "def is_time(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def process_input(input_list):\n",
    "    result = []\n",
    "    current_sentence = None\n",
    "    prev_is_sentence = False\n",
    "    \n",
    "    for item in input_list:\n",
    "        if is_time(item):\n",
    "            if prev_is_sentence:\n",
    "                # 前一个元素是句子，直接添加时间\n",
    "                result.append(item)\n",
    "                prev_is_sentence = False\n",
    "            else:\n",
    "                # 前一个不是句子，需要补充句子和时间\n",
    "                if current_sentence is not None:\n",
    "                    result.append(current_sentence)\n",
    "                    result.append(item)\n",
    "                    prev_is_sentence = False\n",
    "                # 如果current_sentence是None，则忽略（根据题目描述，输入的第一个元素是句子）\n",
    "        else:\n",
    "            # 处理句子\n",
    "            result.append(item)\n",
    "            current_sentence = item\n",
    "            prev_is_sentence = True\n",
    "    return result\n",
    "\n",
    "\n",
    "def clipuid2cliptime(origin_narrations, video_uid, clip_uid):\n",
    "    summs = origin_narrations[video_uid]['summaries']\n",
    "    is_match = False\n",
    "    for summ in summs:\n",
    "        if summ['_annotation_uid'] == clip_uid:\n",
    "            is_match = True\n",
    "            break\n",
    "    if not is_match:\n",
    "        return None, None\n",
    "    clip_start_time = summ['start_time']\n",
    "    clip_end_time = summ['end_time']\n",
    "    return clip_start_time, clip_end_time\n",
    "\n",
    "\n",
    "def parse_qa_file(file_path, video_uid, clip_uid):\n",
    "    \"\"\"\n",
    "    解析 .txt 文件，将每一组 QA 和任务类型转化为字典\n",
    "    \n",
    "    参数:\n",
    "    - file_path: .txt 文件路径\n",
    "    \n",
    "    返回:\n",
    "    - qa_list: 包含所有 QA 和任务类型的字典列表\n",
    "    \"\"\"\n",
    "    qa_list = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    step_idx = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'Step 2' in line:\n",
    "            step_idx = i\n",
    "    lines = lines[step_idx:]\n",
    "    \n",
    "    clip_start_time, clip_end_time = clipuid2cliptime(origin_narration, video_uid, clip_uid)\n",
    "    if clip_end_time is None:\n",
    "        return []\n",
    "    current_qa = {}\n",
    "    current_a = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        line = line.replace('*', '')\n",
    "        if \"Task Type:\" in line:\n",
    "            current_qa[\"Task Type\"] = line.split(\":\")[1]\n",
    "        elif \"Question:\" in line or \"Q:\" in line:\n",
    "            current_qa[\"question\"] = line.split(\":\")[1].strip()\n",
    "        elif 'Visual cues' in line or 'Visual Cues' in line:\n",
    "            try:\n",
    "                current_qa[\"visual_cues\"] = line\n",
    "            except:\n",
    "                continue\n",
    "        elif \"Answer:\" in line or \"A:\" in line:\n",
    "            current_a.append(line.split(\":\")[1].strip())\n",
    "        elif \"Time:\" in line:\n",
    "            current_a.append(line.split(\":\")[1].strip())\n",
    "        elif line == \"\":\n",
    "            if current_qa:\n",
    "                conversation = []\n",
    "                current_a = process_input(current_a)\n",
    "                    \n",
    "                for i in range(len(current_a)):\n",
    "                    if i % 2 == 0:\n",
    "                        beta = beta_map.get(clip_uid, 0)\n",
    "                        try:\n",
    "                            t = float(current_a[i+1])\n",
    "                        except:\n",
    "                            conversation = []\n",
    "                            break\n",
    "                        start_time = t - beta / (2 * alpha)\n",
    "                        end_time = t + beta / (2 * alpha)\n",
    "                        conversation.append(\n",
    "                            {\n",
    "                                'role': 'assistant',\n",
    "                                'content': current_a[i],\n",
    "                                'time': t,\n",
    "                                'start_time': start_time,\n",
    "                                'end_time': end_time,\n",
    "                            }\n",
    "                        )\n",
    "                if conversation:\n",
    "                    current_qa[\"conversation\"] = conversation\n",
    "                    qa_list.append(current_qa)\n",
    "                current_qa = {}\n",
    "                current_a = []\n",
    "    # 添加最后一组 QA（如果文件末尾没有空行）\n",
    "    if current_qa:\n",
    "        conversation = []\n",
    "        current_a = process_input(current_a)\n",
    "        for i in range(len(current_a)):\n",
    "            if i % 2 == 0:\n",
    "                beta = beta_map.get(clip_uid, 0)\n",
    "                try:\n",
    "                    t = float(current_a[i+1])\n",
    "                except:\n",
    "                    conversation = []\n",
    "                    break\n",
    "                start_time = t - beta / (2 * alpha)\n",
    "                end_time = t + beta / (2 * alpha)\n",
    "                conversation.append(\n",
    "                    {\n",
    "                        'role': 'assistant',\n",
    "                        'content': current_a[i],\n",
    "                        'time': t,\n",
    "                        'start_time': start_time,\n",
    "                        'end_time': end_time,\n",
    "                    }\n",
    "                )\n",
    "        if conversation:\n",
    "            current_qa[\"conversation\"] = conversation\n",
    "            qa_list.append(current_qa)\n",
    "\n",
    "        \n",
    "    for qa in qa_list:\n",
    "        qa[\"clip_start_time\"]=clip_start_time\n",
    "        qa[\"clip_end_time\"]=clip_end_time\n",
    "    return qa_list\n",
    "\n",
    "version = 'move_action_function_train_0_merge_reason'\n",
    "postfix = 'qa.txt'\n",
    "output_dir = f'/home/zhangyl/videollm-online/dataset/{version}/'\n",
    "file_list = os.listdir(output_dir)\n",
    "alpha = 2.5\n",
    "annos = {}\n",
    "for file in file_list:\n",
    "    if file.endswith(postfix):\n",
    "        video_uid, clip_uid = file.split('_')[:2]\n",
    "        if video_uid not in annos:\n",
    "            annos[video_uid] = {}\n",
    "        annos[video_uid][clip_uid] = parse_qa_file(os.path.join(output_dir, file),\n",
    "                                                   video_uid, clip_uid)\n",
    "\n",
    "with open(f'/home/zhangyl/videollm-online/data/estp/annotations/{version}.json', 'w') as f:\n",
    "    json.dump(annos,f, indent=4)\n",
    "\n",
    "# file = 'ffb6dfc1-d2f9-45b1-8e25-2c7d0f32d635_ebff91cf-95ff-4cb1-95ae-cfbd10b77829_qa.txt'\n",
    "# video_uid, clip_uid = file.split('_')[:2]\n",
    "# a = parse_qa_file(os.path.join(output_dir, file),\n",
    "#                                                    video_uid, clip_uid)\n",
    "\n",
    "# print(json.dumps(a, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in annos.items():\n",
    "    for kk,vv in annos[k].items():\n",
    "        for qa in vv:\n",
    "            if 'question' not in qa:\n",
    "                print(k, kk, qa)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The object you lift is a golf club.\n",
      "Time: 540.3254366666666\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 541.4301566666667\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 544.6587366666666\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 548.5609166666667\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 551.5269866666666\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 585.1917866666666\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 589.7279466666666\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 609.1992066666667\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 661.8628866666667\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 671.2641066666666\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 680.7280166666667\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 691.8049766666667\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 740.0249166666666\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 756.9704666666667\n",
      "Sentence: The object you lift is a golf club.\n",
      "Time: 759.5288066666667\n"
     ]
    }
   ],
   "source": [
    "def is_time(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def process_input(input_list):\n",
    "    result = []\n",
    "    current_sentence = None\n",
    "    prev_is_sentence = False\n",
    "    \n",
    "    for item in input_list:\n",
    "        if is_time(item):\n",
    "            if prev_is_sentence:\n",
    "                # 前一个元素是句子，直接添加时间\n",
    "                result.append(item)\n",
    "                prev_is_sentence = False\n",
    "            else:\n",
    "                # 前一个不是句子，需要补充句子和时间\n",
    "                if current_sentence is not None:\n",
    "                    result.append(current_sentence)\n",
    "                    result.append(item)\n",
    "                    prev_is_sentence = False\n",
    "                # 如果current_sentence是None，则忽略（根据题目描述，输入的第一个元素是句子）\n",
    "        else:\n",
    "            # 处理句子\n",
    "            result.append(item)\n",
    "            current_sentence = item\n",
    "            prev_is_sentence = True\n",
    "    return result\n",
    "\n",
    "# 示例输入（根据用户提供的例子构造）\n",
    "input_example = [\n",
    "    'The object you lift is a golf club.',  # 00\n",
    "    '540.3254366666666',                    # 01\n",
    "    'The object you lift is a golf club.',  # 02\n",
    "    '541.4301566666667',                    # 03\n",
    "    'The object you lift is a golf club.',  # 04\n",
    "    '544.6587366666666',                    # 05\n",
    "    'The object you lift is a golf club.',  # 06\n",
    "    '548.5609166666667',                    # 07\n",
    "    'The object you lift is a golf club.',  # 08\n",
    "    '551.5269866666666',                    # 09\n",
    "    'The object you lift is a golf club.',  # 10\n",
    "    '585.1917866666666',                    # 11\n",
    "    'The object you lift is a golf club.',  # 12\n",
    "    '589.7279466666666',                    # 13\n",
    "    'The object you lift is a golf club.',  # 14\n",
    "    '609.1992066666667',                    # 15\n",
    "    'The object you lift is a golf club.',  # 16\n",
    "    '661.8628866666667',                    # 17\n",
    "    'The object you lift is a golf club.',  # 18\n",
    "    '671.2641066666666',                    # 19\n",
    "    'The object you lift is a golf club.',  # 20\n",
    "    '680.7280166666667',                    # 21\n",
    "    'The object you lift is a golf club.',  # 22\n",
    "    '691.8049766666667',                    # 23\n",
    "    'The object you lift is a golf club.',  # 24\n",
    "    '740.0249166666666',                    # 25\n",
    "    'The object you lift is a golf club.',  # 26\n",
    "    '756.9704666666667',                    # 27\n",
    "    '759.5288066666667'                     # 28\n",
    "]\n",
    "\n",
    "processed_list = process_input(input_example)\n",
    "\n",
    "# 打印处理后的结果，验证是否正确\n",
    "for i in range(0, len(processed_list), 2):\n",
    "    if i+1 < len(processed_list):\n",
    "        print(f\"Sentence: {processed_list[i]}\")\n",
    "        print(f\"Time: {processed_list[i+1]}\")\n",
    "    else:\n",
    "        print(f\"Sentence: {processed_list[i]}\")\n",
    "\n",
    "# 如果需要输出为列表，可以直接使用 processed_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videollm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
